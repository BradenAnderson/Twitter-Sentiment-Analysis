{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_vaderSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZ1CUDGvjscniztkyl2yDG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ad7679f32054d6ca7849e1dac3b4c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_02cf33be53c44fe8aa82e764ae9a3688",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8750c80029114a71b85c32fa20806eb9",
              "IPY_MODEL_9b7307440c4a4241a78a76164f26d7a5"
            ]
          }
        },
        "02cf33be53c44fe8aa82e764ae9a3688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8750c80029114a71b85c32fa20806eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_77045328433e46aa9a79c27063b2607c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9eb48ea618643a784606bd06ed4737f"
          }
        },
        "9b7307440c4a4241a78a76164f26d7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40a53d98b2fd4064818c55a1528dc773",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:17&lt;00:00, 25.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cdb609e5e3f40c4ae6c3bc857208b83"
          }
        },
        "77045328433e46aa9a79c27063b2607c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9eb48ea618643a784606bd06ed4737f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40a53d98b2fd4064818c55a1528dc773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cdb609e5e3f40c4ae6c3bc857208b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a5a3cb927844b498794818f3d489409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a283f6c58e4c4c898da1743acecbf5b8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cb378e4a736458990395ea6c8a91e73",
              "IPY_MODEL_5152e4f8b13b4bcea113c54735cd0762"
            ]
          }
        },
        "a283f6c58e4c4c898da1743acecbf5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cb378e4a736458990395ea6c8a91e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d72d1c86c4864db9b62dac2f67700838",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a3ac44eb5194a649f5b2831de055165"
          }
        },
        "5152e4f8b13b4bcea113c54735cd0762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6b52adc538f4873a0aa844fa4f1913e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:16&lt;00:00, 25.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cad3643678144d57875d13dc46b65fd3"
          }
        },
        "d72d1c86c4864db9b62dac2f67700838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a3ac44eb5194a649f5b2831de055165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6b52adc538f4873a0aa844fa4f1913e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cad3643678144d57875d13dc46b65fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c99b1d897614e1e9608050b8ddc9326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c8e6b128adf4c0996eaf9db63eb660e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4f6ce7fd6d44061bc994a91e9dcf0af",
              "IPY_MODEL_1bbf1f7d2c3a4d74abca33261de8f0d1"
            ]
          }
        },
        "0c8e6b128adf4c0996eaf9db63eb660e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4f6ce7fd6d44061bc994a91e9dcf0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a8fbdcae6e44266a1bcb57656bff773",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a9a994bc92048ad9228f71b48174a9f"
          }
        },
        "1bbf1f7d2c3a4d74abca33261de8f0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58477cf0d21a4016a48fe5de7e043ddc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 228kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0eb2874bd575414b940c382920808307"
          }
        },
        "9a8fbdcae6e44266a1bcb57656bff773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a9a994bc92048ad9228f71b48174a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58477cf0d21a4016a48fe5de7e043ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0eb2874bd575414b940c382920808307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7277e530017419ead7058ccec7d264e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9fa9a3bab754e308136770ac1cfc479",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff4d29b8920e4515b206e8b94beef58a",
              "IPY_MODEL_121fdee9fe54400988e1303feb8c5798"
            ]
          }
        },
        "b9fa9a3bab754e308136770ac1cfc479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff4d29b8920e4515b206e8b94beef58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ca1c0489ae0429ba73d134a16e2e006",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb9f48ea6ab6446180d08a4046e097f5"
          }
        },
        "121fdee9fe54400988e1303feb8c5798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_121e905e20524ffca1836b673ad37350",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 91.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f35cd4c14e8342a8af8b0ceed0e752c6"
          }
        },
        "9ca1c0489ae0429ba73d134a16e2e006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb9f48ea6ab6446180d08a4046e097f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "121e905e20524ffca1836b673ad37350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f35cd4c14e8342a8af8b0ceed0e752c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e0e9f83b164454182f740c4098f5681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a82dd854978448a1818cde4e625ae5f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f89889d3b207437ba847c6eeae4b540c",
              "IPY_MODEL_329738703b9d4c2ebfcdf3cdca85b054"
            ]
          }
        },
        "a82dd854978448a1818cde4e625ae5f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f89889d3b207437ba847c6eeae4b540c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9935139196f046d682d0494cbd5042c6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d92782fcd59b44b2b65dcda2c40f7a0f"
          }
        },
        "329738703b9d4c2ebfcdf3cdca85b054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a508e1fb4b9143bab807fd36f71adc16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 1.86MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8168433c9a54deaa79df9286bf1b45f"
          }
        },
        "9935139196f046d682d0494cbd5042c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d92782fcd59b44b2b65dcda2c40f7a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a508e1fb4b9143bab807fd36f71adc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8168433c9a54deaa79df9286bf1b45f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BradenAnderson/Twitter-Sentiment-Analysis/blob/main/02_vaderSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKaDlEdDkCci",
        "outputId": "2b9830c3-f314-4aa3-d540-ab4061f0c679"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7vyYEPhiPFW"
      },
      "source": [
        "!pip install -q torch==1.4.0, torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZDbI0cV4xQz"
      },
      "source": [
        "# Clone the neuspell github repository and install its contents. This is used to explore spell checking capabilities. \n",
        "!git clone https://github.com/neuspell/neuspell\n",
        "!pip install /content/neuspell/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c25sNW8dtOTd"
      },
      "source": [
        "!pip install -r /content/neuspell/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1pMSnKpj0sY"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from neuspell import BertChecker\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qIGcbm3iRo-"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3A6dWTfkFFS"
      },
      "source": [
        "pd.set_option('display.max_rows', 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "c0Y8iRlwG2qq",
        "outputId": "9d75f13d-12ea-4738-f283-6c793a996090"
      },
      "source": [
        "# Read in the tweet dataset that was output by the 01_Data_Cleaning_With_Spacy notebook.\n",
        "filename = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/train_tweets_spacy_clean.csv\"\n",
        "cleaned_tweet_df = pd.read_csv(filename)\n",
        "\n",
        "# Remove columns we don't need and display the first five rows of the DataFrame.\n",
        "cleaned_tweet_df.drop(columns=['tweet_emoji_cleaned', 'Fully_Clean_Tweet_Tokenized'], inplace=True)\n",
        "cleaned_tweet_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>Clean_Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father dysfunctional significant selfish pron ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thank #lyft credit use cause pron offer wheelc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday pron majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model love pron pron time pron happy love hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                        Clean_Tweet\n",
              "0      0  ...  father dysfunctional significant selfish pron ...\n",
              "1      0  ...  thank #lyft credit use cause pron offer wheelc...\n",
              "2      0  ...                                bihday pron majesty\n",
              "3      0  ...  #model love pron pron time pron happy love hap...\n",
              "4      0  ...                     factsguide society #motivation\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "PMRs3mQLkFky",
        "outputId": "e39aecba-4970-4da0-9cb4-b5d41bd951a0"
      },
      "source": [
        "# Read in the tweet dataset output by the 00_Emoji_Data_Cleaning notebook. (Emojis have been cleaned but the rest of the tweet has not be preprocessed yet).\n",
        "filename = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/train_test_data/train_twitter_sentiment.csv\"\n",
        "tweet_df = pd.read_csv(filename, index_col=0)\n",
        "\n",
        "# Make a copy of this DataFrame for later use. \n",
        "original_tweet_df = tweet_df.copy(deep=True)\n",
        "\n",
        "# Display the first five rows.\n",
        "tweet_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label                                              tweet\n",
              "id                                                          \n",
              "1       0   @user when a father is dysfunctional and is s...\n",
              "2       0  @user @user thanks for #lyft credit i can't us...\n",
              "3       0                                bihday your majesty\n",
              "4       0  #model   i love u take with u all the time in ...\n",
              "5       0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmMg1VbfDOKr"
      },
      "source": [
        "# Part 1 - Set up vaderSentiment and create a baseline classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-o6RqIOT0Ma"
      },
      "source": [
        "# Initialize the vaderSentiment SentimentIntensityAnalyzer. \n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxmL3aefUi08"
      },
      "source": [
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Inputs: A given dataframe, sentiment analyzer (default defined at start of notebook), and column name within the dataframe (default is 'tweet'). \n",
        "# Output: The input dataframe with a new 'Positive_Sentiment_Score' column added. This new column contains the \"positive\" portion of the\n",
        "# vaderSentiment polarity score for the associated item in the tweet column.\n",
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def add_positive_score_column(df, sentiment_analyzer=sentiment_analyzer, text_to_score_column='tweet'):\n",
        "\n",
        "  df['Positive_Sentiment_Score'] = df[text_to_score_column].apply(lambda x : sentiment_analyzer.polarity_scores(x)['pos'])\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nFDXCpyXKEA"
      },
      "source": [
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Inputs: A given dataframe, sentiment analyzer (default defined at start of notebook), and column name within the dataframe (default is 'tweet'). \n",
        "# Output: The input dataframe with a new 'Negative_Sentiment_Score' column added. This new column contains the \"positive\" portion of the\n",
        "# vaderSentiment polarity score for the associated item in the tweet column.\n",
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def add_negative_score_column(df, sentiment_analyzer=sentiment_analyzer, text_to_score_column='tweet'):\n",
        "\n",
        "  df['Negative_Sentiment_Score'] = df[text_to_score_column].apply(lambda x : sentiment_analyzer.polarity_scores(x)['neg'])\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMO7GJaDXgXB"
      },
      "source": [
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Inputs: A given dataframe, sentiment analyzer (default defined at start of notebook), and column name within the dataframe (default is 'tweet'). \n",
        "# Output: The input dataframe with a new 'Neutral_Sentiment_Score' column added. This new column contains the \"neutral\" portion of the\n",
        "# vaderSentiment polarity score for the associated item in the tweet column.\n",
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def add_neutral_score_column(df, sentiment_analyzer=sentiment_analyzer, text_to_score_column='tweet'):\n",
        "\n",
        "  df['Neutral_Sentiment_Score'] = df[text_to_score_column].apply(lambda x : sentiment_analyzer.polarity_scores(x)['neu'])\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T3m5xu0XrHQ"
      },
      "source": [
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Inputs: A given dataframe, sentiment analyzer (default defined at start of notebook), and column name within the dataframe (default is 'tweet'). \n",
        "# Output: The input dataframe with a new 'Compound_Sentiment_Score' column added. This new column contains the \"compound\" portion of the\n",
        "# vaderSentiment polarity score for the associated item in the tweet column.\n",
        "#\n",
        "# Note: If a single metric is needed, compound score is the one to use. This is a measurement of sentiment intesnsity, normalized to \n",
        "# between -1 (most negative) to +1 (most positive).\n",
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def add_compound_score_column(df, sentiment_analyzer=sentiment_analyzer, text_to_score_column='tweet'):\n",
        "\n",
        "  df['Compound_Sentiment_Score'] = df[text_to_score_column].apply(lambda x : sentiment_analyzer.polarity_scores(x)['compound'])\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MonRCosX57C"
      },
      "source": [
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# If all of the vaderSentiment score types are desired, this function uses the four above functions to add each score type to the \n",
        "# dataframe as its own column.\n",
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def add_sentiment_score_columns(df, sentiment_analyzer=sentiment_analyzer, text_to_score_column='tweet'): \n",
        "\n",
        "  df = add_positive_score_column(df, sentiment_analyzer, text_to_score_column)\n",
        "  df = add_negative_score_column(df, sentiment_analyzer, text_to_score_column)\n",
        "  df = add_neutral_score_column(df, sentiment_analyzer, text_to_score_column)\n",
        "  df = add_compound_score_column(df, sentiment_analyzer, text_to_score_column)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YFRlHzBwpnh"
      },
      "source": [
        "# Takes in a single tweet string and returns a list of sentence tokens.\n",
        "def tokenize_tweet(tweet): \n",
        "\n",
        "  tweet_sentence_tokens = sent_tokenize(tweet)\n",
        "  \n",
        "  return tweet_sentence_tokens\n",
        "\n",
        "# Applys the function above to every column in the specified DataFrame. Creates a new column containing a list\n",
        "# of sentence tokens for the associated tweet.\n",
        "def add_sentence_tokens_column(df, tweet_text_column='tweet', tokenized_tweet_column='Tokenized_Tweet'):\n",
        "\n",
        "  df[tokenized_tweet_column] = df[tweet_text_column].apply(tokenize_tweet)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuwxx_dzukQv"
      },
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# This is a helper function used by the sentence_analysis_score function when calculating the average value of one or more of the vader sentiment scores.\n",
        "# It returns the number of scores being averaged provided that at least 1 score exists. If an attempt is made to average 0 items, this function returns\n",
        "# 1 to avoid a divide by zero condition. \n",
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def get_denominator(score_type, score_dict):\n",
        "\n",
        "  denominator = 1\n",
        "\n",
        "  if score_type == 'compound' and len(score_dict['Compound']) > 1: \n",
        "    denominator = len(score_dict['Compound'])\n",
        "  elif score_type == 'pos' and len(score_dict['Positive']) > 1:\n",
        "    denominator = len(score_dict['Positive'])\n",
        "  elif score_type == 'neg' and len(score_dict['Negative']) > 1:\n",
        "    denominator = len(score_dict['Negative'])\n",
        "  elif score_type == 'neu' and len(score_dict['Neutral']) > 1:\n",
        "    denominator = len(score_dict['Neutral'])\n",
        "  \n",
        "  return denominator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSLgWihgzhP_"
      },
      "source": [
        "# Takes in a list of sentence tokens and returns the average compound score for the tokens in the list.\n",
        "def sentence_analysis_score(tweet_sentence_tokens, sentiment_analyzer=sentiment_analyzer, score_type='compound'):\n",
        "\n",
        "  score_dict = {'Positive' : [],\n",
        "                'Negative' : [],\n",
        "                'Neutral' : [],\n",
        "                'Compound' : []}\n",
        "  \n",
        "  for sentence in tweet_sentence_tokens: \n",
        "    score = sentiment_analyzer.polarity_scores(sentence)\n",
        "    score_dict['Positive'].append(score['pos'])\n",
        "    score_dict['Negative'].append(score['neg'])\n",
        "    score_dict['Neutral'].append(score['neu'])\n",
        "    score_dict['Compound'].append(score['compound'])\n",
        "\n",
        "  denominator = get_denominator(score_type, score_dict)\n",
        "\n",
        "  if score_type == 'compound':\n",
        "    average_compound_score = sum(score_dict['Compound']) / denominator\n",
        "    return average_compound_score\n",
        "  elif score_type == 'pos':\n",
        "    average_positive_score = sum(score_dict['Positive']) / denominator\n",
        "    return average_positive_score\n",
        "  elif score_type == 'neg':\n",
        "    average_negative_score = sum(score_dict['Negative']) / denominator\n",
        "    return average_negative_score\n",
        "  elif score_type == 'neu':\n",
        "    average_neutral_score = sum(score_dict['Neutral']) / denominator\n",
        "    return average_neutral_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I3NhoB-3CZ6"
      },
      "source": [
        "#---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Creates a new column in the dataframe where the values are the compound score for the associated tweet, calculated by first breaking the tweet up into\n",
        "# sentence level tokens, and then average the score for each token.\n",
        "#---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def add_sentence_level_compound_score_column(df, sentiment_analyzer=sentiment_analyzer, tweet_text_column='tweet', text_to_score_column='Tokenized_Tweet', keep_subscores=False,\n",
        "                                             sub_scores=None):\n",
        "\n",
        "  # A list of valid subscores. If the user is specifying particular subscore columns to keep, they are checked against this to make sure they are valid scores.\n",
        "  valid_subscores = ['pos', 'neg', 'neu', 'compound']\n",
        "\n",
        "  # Get a list of column names for the dataframe that was passed in.\n",
        "  df_column_names = list(df.columns)\n",
        "\n",
        "  # If the dataframe already has a column containing sentence level tokens.\n",
        "  if text_to_score_column in df_column_names: \n",
        "\n",
        "    # If the user does not want to keep subscore columns.\n",
        "    if keep_subscores == False:\n",
        "\n",
        "      # Apply the sentence_analysis score function to each list of sentence tokens to get the average compound score for that tweet.\n",
        "      df['Sentence_Level_Compound_Score'] = df[text_to_score_column].apply(sentence_analysis_score, args=(sentiment_analyzer, 'compound'))\n",
        "\n",
        "      return df\n",
        "\n",
        "    # If we also want to add dataframe columns for the 'pos', 'neg' and 'neu' subscores (or a subset of them).\n",
        "    elif keep_subscores == True:\n",
        "\n",
        "      # Figure out which subscore to keep, if not specified or incorrectly specified, use them all. \n",
        "      if sub_scores is None or type(sub_scores) != list or not all(scores in valid_subscores for scores in sub_scores):\n",
        "        sub_scores = valid_subscores\n",
        "\n",
        "      # Create each subscore column.\n",
        "      for score in sub_scores:\n",
        "        column_name = 'Sentence_Level_' + score + \"_Score\"\n",
        "        df[column_name] = df[text_to_score_column].apply(sentence_analysis_score, args=(sentiment_analyzer, score))\n",
        "\n",
        "      return df\n",
        "      \n",
        "  # Else, we do not already have a column with sentence level tokens in the dataframe. We will need to make a temporary\n",
        "  # column with sentence level tokenizations so we can use it to calculate the sentence level scores.\n",
        "  else: \n",
        "\n",
        "    # Create a column of setence level tokens.\n",
        "    df = add_sentence_tokens_column(df, tweet_text_column=tweet_text_column, tokenized_tweet_column=text_to_score_column)\n",
        "\n",
        "    # When returning the dataframe keep all specified subscores.\n",
        "    if keep_subscores == True:\n",
        "\n",
        "      # Figure out which subscore to keep, if not specified or incorrectly specified, use them all. \n",
        "      if sub_scores is None or type(sub_scores) != list or not all(scores in valid_subscores for scores in sub_scores):\n",
        "        sub_scores = valid_subscores\n",
        "\n",
        "      # Create each subscore column.\n",
        "      for score in sub_scores:\n",
        "        column_name = 'Sentence_Level_' + score + \"_Score\"\n",
        "        df[column_name] = df[text_to_score_column].apply(sentence_analysis_score, args=(sentiment_analyzer, score))\n",
        "\n",
        "    elif keep_subscores == False: \n",
        "\n",
        "      # Create the sentence level compound score column.\n",
        "      df['Sentence_Level_Compound_Score'] = df[text_to_score_column].apply(sentence_analysis_score, args=(sentiment_analyzer,))\n",
        "\n",
        "    # Drop the column of sentence level tokens. This was not part of the df when the function was called, \n",
        "    # and was only used as an intermediate processing step. \n",
        "    df.drop(columns=[text_to_score_column], inplace=True)\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_bqcUxNABE3"
      },
      "source": [
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# This function uses the compound sentiment score generated by vaderSentiment to classify tweets as either \"hate speech\" or \"not hate speech\".\n",
        "#\n",
        "# Inputs: A dataframe containing the tweets that need to be classified, as well as optional parameters for the sentiment analyzer, tweet column,\n",
        "# threshold, and sentence level analysis.\n",
        "#\n",
        "# Output: The input dataframe with a new column added. This new column will be 1 (indicating contains hate speech) for rows where the associated\n",
        "# tweet had a compound sentiment score less than threshold (tweet was deemed more negative than the threshold value), and 0 (does not contain hate speech) \n",
        "# for rows where the associated tweet had a compound sentiment score higher than threshold (tweet more positive than the threshold setting).\n",
        "# \n",
        "# Note: The sentence_level_analysis parameter determines how to calculate the decision boundary. If this parameter is set to True, vader will \n",
        "# calculate a compound score for each sentence in the tweet individually, and then the average compound score will become the decision boundary. If \n",
        "# this is set to False, then vader will calculate a single compound score for the entire tweet and no averaging is required. \n",
        "#\n",
        "# Note: The threshold parameter sets the decision boundry for hate speech classification. Tweets with a compound score above the decision\n",
        "# boundary are not classified as hate speech, while tweets below the decision boundry are classified as hate speech\n",
        "#\n",
        "# Note: This function may need to create intermediate columns in the Dataframe to perform calculations, however it is designed to return the\n",
        "# DataFrame with only the columns it had when the function was called, with the exception of the prediction column being added (intermediate columns\n",
        "# are removed before the function returns). \n",
        "# \n",
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def add_classification_predictions_column(df, sentiment_analyzer=sentiment_analyzer, text_column='tweet', threshold=0.0,\n",
        "                                          sentence_level_analysis = False): \n",
        "\n",
        "  df_column_names = list(df.columns)\n",
        "\n",
        "  if 'Compound_Sentiment_Score' in df_column_names and sentence_level_analysis == False:\n",
        "\n",
        "    df['Predicted_Class'] = df['Compound_Sentiment_Score'].apply(lambda score : 1 if score < threshold else 0)\n",
        "\n",
        "    return df\n",
        "\n",
        "  elif 'Compound_Sentiment_Score' not in df_column_names and sentence_level_analysis == False: \n",
        "\n",
        "    df = add_compound_score_column(df, sentiment_analyzer, text_column)\n",
        "\n",
        "    df['Predicted_Class'] = df['Compound_Sentiment_Score'].apply(lambda score : 1  if score < threshold else 0)\n",
        "\n",
        "    df.drop(columns=['Compound_Sentiment_Score'], inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "  elif 'Sentence_Level_Compound_Score' in df_column_names and sentence_level_analysis == True:\n",
        "\n",
        "    df['Predicted_Class_Sentence_Level'] = df['Sentence_Level_Compound_Score'].apply(lambda score : 1 if score < threshold else 0)\n",
        "\n",
        "    return df\n",
        "  \n",
        "  elif 'Sentence_Level_Compound_Score' not in df_column_names and sentence_level_analysis == True:\n",
        "\n",
        "    df = add_sentence_level_compound_score_column(df, sentiment_analyzer, text_column)\n",
        "\n",
        "    df['Predicted_Class_Sentence_Level'] = df['Sentence_Level_Compound_Score'].apply(lambda score : 1 if score < threshold else 0)\n",
        "\n",
        "    df.drop(columns=['Sentence_Level_Compound_Score'], inplace=True)\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqJ_26oSh_Q-"
      },
      "source": [
        "# This function calculates sensitivity with the foluma TP/(TP + FN)\n",
        "def calculate_sensitiviy(true_positives, false_negatives): \n",
        "  return true_positives / (true_positives + false_negatives)\n",
        "\n",
        "# This function calculates specificity with the foluma TN/(TN + FP)\n",
        "def calculate_specificity(true_negatives, false_positives):\n",
        "  return true_negatives / (true_negatives + false_positives)\n",
        "\n",
        "# This function calculates precision with the foluma TP/(TP + FP)\n",
        "def calculate_precision(true_positives, false_positives): \n",
        "  return true_positives / (true_positives + false_positives)\n",
        "\n",
        "# This function calculates accuracy with the foluma (TP + TN)/(TP + TN + FP + FN)\n",
        "def calculate_accuracy(true_negatives, false_positives, false_negatives, true_positives): \n",
        "  return (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un76J11XFMxg"
      },
      "source": [
        "# This function recieves dictionary, and four values (TP, FP, FN, TP) as inputs. \n",
        "# This function simply adds the four input values to the input dictionary and returns the dictionary.\n",
        "def add_confusion_params(input_dict, true_negatives, false_positives, false_negatives, true_positives): \n",
        "  input_dict['True_Negatives'] = true_negatives\n",
        "  input_dict['False_Positives'] = false_positives\n",
        "  input_dict['False_Negatives'] = false_negatives\n",
        "  input_dict['True_Positives'] = true_positives\n",
        "  return input_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_OidAP_XC7K"
      },
      "source": [
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# This function uses the helper functions above to create a dictionary of the classification metrics and their values. \n",
        "#\n",
        "# This function is a helper function to the get_classification_metrics function.\n",
        "#\n",
        "# Inputs: The confusion matrix parameters (true negatives, false positives, false negatives, true positives) and a list of metric names\n",
        "# to calculate (metrics_to_calculate). \n",
        "#\n",
        "# Output: A dictionary containing calculated values for the desired metrics.\n",
        "# \n",
        "# Note: If the parameter \"verbose\" is set to True additional information will be added to the output dictionary that shows, for each metric, \n",
        "# the value of all the intermediate metrics (TP, TN, etc.) that were used to calculate it.\n",
        "#\n",
        "# Note: The include_confusion_params parameter is set to True then separate entries will be added to the dictionary for each \n",
        "# confusion matrix parameter (TP, TN, FP, FN).\n",
        "#\n",
        "#---------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def calculate_metrics(true_negatives, false_positives, false_negatives, true_positives, metrics_to_calculate, verbose, include_confusion_params): \n",
        "\n",
        "  metrics = {}\n",
        "\n",
        "  if 'Sensitivity' in metrics_to_calculate and not verbose: \n",
        "    metrics['Sensitivity'] = calculate_sensitiviy(true_positives, false_negatives)\n",
        "  elif 'Sensitivity' in metrics_to_calculate and verbose:\n",
        "    sensitivity = calculate_sensitiviy(true_positives, false_negatives)\n",
        "    metrics['Sensitivity'] = [sensitivity, \"True Positives: \" + str(true_positives), \"False Negatives: \" + str(false_negatives)]\n",
        "  \n",
        "  if 'Specificity' in metrics_to_calculate and not verbose: \n",
        "    metrics['Specificity'] = calculate_specificity(true_negatives, false_positives)\n",
        "  elif 'Specificity' in metrics_to_calculate and verbose: \n",
        "    specificity = calculate_specificity(true_negatives, false_positives)\n",
        "    metrics['Specificity'] = [specificity, \"True Negatives: \" + str(true_negatives), \"False Positives: \" + str(false_positives)]\n",
        "  \n",
        "  if 'Precision' in metrics_to_calculate and not verbose:\n",
        "    metrics['Precision'] = calculate_precision(true_positives, false_positives)\n",
        "  elif 'Precision' in metrics_to_calculate and verbose:\n",
        "    precision = calculate_precision(true_positives, false_positives)\n",
        "    metrics['Precision'] = [precision, \"True Positives: \" + str(true_positives), \"False Positives: \" + str(false_positives)]\n",
        "\n",
        "  if 'Accuracy' in metrics_to_calculate and not verbose:\n",
        "    metrics['Accuracy'] = calculate_accuracy(true_negatives, false_positives, false_negatives, true_positives)\n",
        "  elif 'Accuracy' in metrics_to_calculate and verbose: \n",
        "    accuracy = calculate_accuracy(true_negatives, false_positives, false_negatives, true_positives)\n",
        "    metrics['Accuracy'] = [accuracy, \"True Positives: \" + str(true_positives), \"True Negatives: \" + str(true_negatives), \n",
        "                           \"False Positives: \" + str(false_positives), \"False Negatives: \" + str(false_negatives)]\n",
        "  \n",
        "\n",
        "  if(include_confusion_params == True): \n",
        "    metrics = add_confusion_params(metrics, true_negatives, false_positives, false_negatives, true_positives)\n",
        "\n",
        "\n",
        "  return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn54GkduZIWB"
      },
      "source": [
        "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# This function uses the scikit-learn confusion matrix to calculate various classification metrics.\n",
        "# \n",
        "# Required Inputs: A dataframe containing tweet text being classified, and the correct labels (hate speech or not) for each tweet.\n",
        "# \n",
        "# Optional Inputs: 1) The name of the dataframe column containing the tweets text (if excluded it is assumed to be 'tweet')\n",
        "#                  2) The name of the dataframe column containing the ground truth labels (if excluded it is assumed to be 'label')\n",
        "#                  3) A list of metrics to calculate. (if excluded, the list is assumed to be Sensitivity, Specificity, Precision, and Accuracy)\n",
        "#                  4) The sentiment intensity analyzer to use (if excluded, the one defined at the start of this notebook is used).\n",
        "#                  5) What the classification decision boundary should be (if exluded, it is assumed to be zero, meaning compound scores above zero are not hate speech).\n",
        "#                  6) If the vader compound score should be calculated sentence by sentence then averaged, or once for the entire tweet (if excluded, assumes once for the tweet).\n",
        "#                  7) Whether or not the confusion matrix parameters themselves (TP, TP, FP, FN) need their own dictionary entries. (if exlcuded, assumes no). \n",
        "#\n",
        "# Outputs: A dictionary containing values for the desired metrics.\n",
        "#\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def get_classification_metrics(df, tweet_text_column='tweet', ground_truth_column_name='label', metrics_list = None, verbose = False,\n",
        "                               sentiment_analyzer=sentiment_analyzer, threshold=0.0, sentence_level_analysis=False, include_confusion_params=False):\n",
        "\n",
        "  if metrics_list is None or type(metrics_list) != list:\n",
        "    metrics_list = ['Sensitivity', 'Specificity', 'Precision', 'Accuracy']\n",
        "\n",
        "  if sentence_level_analysis == False:\n",
        "    prediction_column_name = 'Predicted_Class'\n",
        "  else:\n",
        "    prediction_column_name = 'Predicted_Class_Sentence_Level'\n",
        "\n",
        "  df_column_names = list(df.columns)\n",
        "\n",
        "  if prediction_column_name in df_column_names: \n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(df[ground_truth_column_name], df[prediction_column_name]).ravel()\n",
        "\n",
        "    classification_metrics = calculate_metrics(tn, fp, fn, tp, metrics_list, verbose, include_confusion_params)\n",
        "  \n",
        "    return classification_metrics\n",
        "\n",
        "  elif prediction_column_name not in df_column_names: \n",
        "\n",
        "    df = add_classification_predictions_column(df, sentiment_analyzer=sentiment_analyzer, text_column=tweet_text_column, threshold=threshold, sentence_level_analysis=sentence_level_analysis)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(df[ground_truth_column_name], df[prediction_column_name]).ravel()\n",
        "\n",
        "    classification_metrics = calculate_metrics(tn, fp, fn, tp, metrics_list, verbose, include_confusion_params)\n",
        "\n",
        "    df.drop(columns=[prediction_column_name], inplace = True)\n",
        "\n",
        "    return classification_metrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPTepYKSrZWa",
        "outputId": "58092997-ada4-4747-c4d1-4dd025206703"
      },
      "source": [
        "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# This cell display the classification metrics for the case where vaderSentiment is used to classify the tweets as \"containing hate speech\" or \n",
        "# \"not containing hate speech\" without any preprocessing applied to the tweets. This can be used as a baseline to see if we can improve vaderSentiments\n",
        "# ability to perform this type of classification by applying various data cleaning steps. \n",
        "#\n",
        "# ----------------------------------------------------------------\n",
        "# Review of metric deffinitions in the context of this problem\n",
        "# ----------------------------------------------------------------\n",
        "# Accuracy: The proportion of tweets that were classified correctly.\n",
        "#\n",
        "# Precision: Out of all the tweets the algorithm claimed contained hate speech, how many were correct? \n",
        "# \n",
        "# Sensitivity (i.e. True positive rate or recall): Out of all the tweets that actually did contain hate speech, what percentage were correctly classified?\n",
        "#\n",
        "# Specificity (i.e. True negative rate or selectivity): Out of all the tweets that did not contain hate speech, what percentage were correctly classified?\n",
        "# \n",
        "# -------------------------\n",
        "# Reviewing Scores\n",
        "# -------------------------\n",
        "#\n",
        "# Precision = 0.14. This is a very low precision score, which tells us that we are getting a large number of false positives. This could be due \n",
        "# to the fact that we currently are using the compound_score=0 threshold to determine if a tweet contains hate speech or not. The vaderSentiment compound\n",
        "# score was designed to take values between -1 and +1, where negative values indicate a \"negative sentiment\" and positive values indicate a \"positive sentiment\".\n",
        "# We can interpret this score to say that there are a lot of tweets with \"negative sentiment\" that are not actually hate speech. \n",
        "#\n",
        "# Sensitivity = 0.39. This score tells us that out of all the tweets that contained hate speech, we correctly classified only 39% of them. Since in this\n",
        "# first simple model we classified all tweets with a negative compound score as being hate speech, this result is a bit suprising. It is saying that only\n",
        "# 39% of the tweets that are hate speech actually have a negative compound score. Precision told us that there are many tweets with negative sentiment (according\n",
        "# to vader) that are not hatespeech, and sensitivity tells us that there are many tweets with positive sentiment (according to vader) that actually are\n",
        "# hate speech. \n",
        "#\n",
        "# Specificity = 0.82. This score tell us that out of all the tweets that do not contain hate speech, we correctly classified 82% of them. In the context of the\n",
        "# model we created, this says that 82% of tweets that do not contain hate speech have a positive sentiment according to vaders compound polarity score.\n",
        "#\n",
        "# Accuracy = 0.79. 79% accuracy is not terrible for a first basic attempt, but I think this value is a little bit misleading and it should not give us\n",
        "# false confidence. In the metrics above we showed that when this model thought something was hate speech, it was correct only 14% of the time, and when something\n",
        "# actually was hate speech it was correct only 39% of the time. This tells us that we have a significant number of false positives (5160) and \n",
        "# false negatives (1357). The fact that the classes in our dataset are greatly uneven (29720 examples of non-hate speech, compared to 2242 examples of hate\n",
        "# speech) is likely making this score higher than it would be if the classes were balanced.\n",
        "#\n",
        "# Note: Our model over-classifies things as hate speech. If the purpose of the model is to filter down a long list of tweets so a human can then hand review\n",
        "# tweets that are likely to contain hate speech, then ensuring all hate speech tweets are correctly classified (even at the expense of misclassifying some\n",
        "# non hate speech tweets) may be the desired balance. (A larger set needs to be reviewed by the human but you don't miss the chance to remove a hateful person\n",
        "# from your platform).\n",
        "# \n",
        "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "metrics = get_classification_metrics(tweet_df, verbose=True)\n",
        "\n",
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': [0.796101620674551,\n",
              "  'True Positives: 885',\n",
              "  'True Negatives: 24560',\n",
              "  'False Positives: 5160',\n",
              "  'False Negatives: 1357'],\n",
              " 'Precision': [0.14640198511166252,\n",
              "  'True Positives: 885',\n",
              "  'False Positives: 5160'],\n",
              " 'Sensitivity': [0.39473684210526316,\n",
              "  'True Positives: 885',\n",
              "  'False Negatives: 1357'],\n",
              " 'Specificity': [0.8263795423956931,\n",
              "  'True Negatives: 24560',\n",
              "  'False Positives: 5160']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlMUQzLhrMw8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "07406fe7-54fe-406f-9be7-eb14d7dcce22"
      },
      "source": [
        "# Base sentiment scores with no data cleaning steps applied. \n",
        "tweet_df = add_sentiment_score_columns(tweet_df, sentiment_analyzer)\n",
        "tweet_df = add_classification_predictions_column(tweet_df)\n",
        "tweet_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>Positive_Sentiment_Score</th>\n",
              "      <th>Negative_Sentiment_Score</th>\n",
              "      <th>Neutral_Sentiment_Score</th>\n",
              "      <th>Compound_Sentiment_Score</th>\n",
              "      <th>Predicted_Class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.385</td>\n",
              "      <td>0.615</td>\n",
              "      <td>-0.8296</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>0.256</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.744</td>\n",
              "      <td>0.6705</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>0.337</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.663</td>\n",
              "      <td>0.7249</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label  ... Predicted_Class\n",
              "id         ...                \n",
              "1       0  ...               1\n",
              "2       0  ...               0\n",
              "3       0  ...               0\n",
              "4       0  ...               0\n",
              "5       0  ...               0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5rwf32gDZxT"
      },
      "source": [
        "# Part 2 - Explore how data cleaning increases (or decreases) vaderSentiments effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00_h5gL5syr-"
      },
      "source": [
        "## Explore how the vader sentiment score changes when twitter handles are removed prior to sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj8tELMFg4Sv"
      },
      "source": [
        "def remove_handles(tweet):\n",
        "\n",
        "  twitter_handle_removed = re.sub('@[^\\s]+','',tweet).rstrip()\n",
        "  twitter_handle_removed = re.sub(\" +\", \" \", twitter_handle_removed)\n",
        "\n",
        "  return twitter_handle_removed\n",
        "\n",
        "def remove_twitter_handles(df, tweet_text_column='tweet', no_handles_column='Tweet_Without_Handles'):\n",
        "\n",
        "  df[no_handles_column] = df[tweet_text_column].apply(remove_handles)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK3qFJ23mJn8",
        "outputId": "e65af600-ad9f-4d23-b70b-f0d65cfa5ef1"
      },
      "source": [
        "tweet_df = remove_twitter_handles(tweet_df)\n",
        "metrics_without_handles = get_classification_metrics(tweet_df, tweet_text_column='Tweet_Without_Handles', verbose=True)\n",
        "\n",
        "metrics_without_handles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': [0.796101620674551,\n",
              "  'True Positives: 885',\n",
              "  'True Negatives: 24560',\n",
              "  'False Positives: 5160',\n",
              "  'False Negatives: 1357'],\n",
              " 'Precision': [0.14640198511166252,\n",
              "  'True Positives: 885',\n",
              "  'False Positives: 5160'],\n",
              " 'Sensitivity': [0.39473684210526316,\n",
              "  'True Positives: 885',\n",
              "  'False Negatives: 1357'],\n",
              " 'Specificity': [0.8263795423956931,\n",
              "  'True Negatives: 24560',\n",
              "  'False Positives: 5160']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Isfm8ctkj1up",
        "outputId": "e0ce0f59-7f88-4d7d-e366-8e32ae0f004f"
      },
      "source": [
        "without_handles_df = add_sentiment_score_columns(tweet_df, text_to_score_column='Tweet_Without_Handles')\n",
        "without_handles_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>Positive_Sentiment_Score</th>\n",
              "      <th>Negative_Sentiment_Score</th>\n",
              "      <th>Neutral_Sentiment_Score</th>\n",
              "      <th>Compound_Sentiment_Score</th>\n",
              "      <th>Predicted_Class</th>\n",
              "      <th>Tweet_Without_Handles</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.402</td>\n",
              "      <td>0.598</td>\n",
              "      <td>-0.8296</td>\n",
              "      <td>1</td>\n",
              "      <td>when a father is dysfunctional and is so self...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>0.282</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.6705</td>\n",
              "      <td>0</td>\n",
              "      <td>thanks for #lyft credit i can't use cause the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>0.337</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.663</td>\n",
              "      <td>0.7249</td>\n",
              "      <td>0</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label  ...                              Tweet_Without_Handles\n",
              "id         ...                                                   \n",
              "1       0  ...   when a father is dysfunctional and is so self...\n",
              "2       0  ...   thanks for #lyft credit i can't use cause the...\n",
              "3       0  ...                                bihday your majesty\n",
              "4       0  ...  #model i love u take with u all the time in ur...\n",
              "5       0  ...                factsguide: society now #motivation\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSO4844RtU9T"
      },
      "source": [
        "## Explore how the vader sentiment score changes when websites are removed prior to sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YcGNgWmvpJ"
      },
      "source": [
        "def remove_web_address(tweet):\n",
        "\n",
        "  tweet_without_website_http = re.sub(r\"http\\S+\", \"\", tweet)\n",
        "  tweet_without_website_www = re.sub(r\"www.\\S+\", \"\", tweet_without_website_http).rstrip()\n",
        "  tweet_without_website = re.sub(\" +\", \" \", tweet_without_website_www)\n",
        "\n",
        "  return tweet_without_website\n",
        "\n",
        "def remove_websites_from_tweets(df, tweet_text_column='tweet', no_website_column='Tweet_Without_Websites'): \n",
        "\n",
        "  df[no_website_column] = df[tweet_text_column].apply(remove_web_address)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bSRPGRJsP2y",
        "outputId": "afbae7af-7c87-44ba-e5de-ebb61bb24ea6"
      },
      "source": [
        "tweet_df = remove_websites_from_tweets(tweet_df)\n",
        "metrics_without_websites = get_classification_metrics(tweet_df, tweet_text_column='Tweet_Without_Websites', verbose=True)\n",
        "\n",
        "metrics_without_websites"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': [0.796101620674551,\n",
              "  'True Positives: 885',\n",
              "  'True Negatives: 24560',\n",
              "  'False Positives: 5160',\n",
              "  'False Negatives: 1357'],\n",
              " 'Precision': [0.14640198511166252,\n",
              "  'True Positives: 885',\n",
              "  'False Positives: 5160'],\n",
              " 'Sensitivity': [0.39473684210526316,\n",
              "  'True Positives: 885',\n",
              "  'False Negatives: 1357'],\n",
              " 'Specificity': [0.8263795423956931,\n",
              "  'True Negatives: 24560',\n",
              "  'False Positives: 5160']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "MGqEM4hMkKSV",
        "outputId": "dec5a252-4bf0-4146-ca4f-39a74d371eeb"
      },
      "source": [
        "without_websites_df = add_sentiment_score_columns(tweet_df, text_to_score_column='Tweet_Without_Websites')\n",
        "without_websites_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>Positive_Sentiment_Score</th>\n",
              "      <th>Negative_Sentiment_Score</th>\n",
              "      <th>Neutral_Sentiment_Score</th>\n",
              "      <th>Compound_Sentiment_Score</th>\n",
              "      <th>Predicted_Class</th>\n",
              "      <th>Tweet_Without_Handles</th>\n",
              "      <th>Tweet_Without_Websites</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.385</td>\n",
              "      <td>0.615</td>\n",
              "      <td>-0.8296</td>\n",
              "      <td>1</td>\n",
              "      <td>when a father is dysfunctional and is so self...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>0.256</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.744</td>\n",
              "      <td>0.6705</td>\n",
              "      <td>0</td>\n",
              "      <td>thanks for #lyft credit i can't use cause the...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>0.337</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.663</td>\n",
              "      <td>0.7249</td>\n",
              "      <td>0</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label  ...                             Tweet_Without_Websites\n",
              "id         ...                                                   \n",
              "1       0  ...   @user when a father is dysfunctional and is s...\n",
              "2       0  ...  @user @user thanks for #lyft credit i can't us...\n",
              "3       0  ...                                bihday your majesty\n",
              "4       0  ...  #model i love u take with u all the time in ur...\n",
              "5       0  ...                factsguide: society now #motivation\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGovozTza9q-"
      },
      "source": [
        "## Explore how the vader sentiment score changes when sentence level analysis is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLXX-6SEFWL-",
        "outputId": "9eb3dd4e-0518-497d-c8ff-3287b37e3964"
      },
      "source": [
        "sentence_level_analysis_metrics = get_classification_metrics(tweet_df, verbose=True, sentence_level_analysis=True)\n",
        "\n",
        "sentence_level_analysis_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': [0.795976472060572,\n",
              "  'True Positives: 887',\n",
              "  'True Negatives: 24554',\n",
              "  'False Positives: 5166',\n",
              "  'False Negatives: 1355'],\n",
              " 'Precision': [0.14653890632744093,\n",
              "  'True Positives: 887',\n",
              "  'False Positives: 5166'],\n",
              " 'Sensitivity': [0.39562890276538804,\n",
              "  'True Positives: 887',\n",
              "  'False Negatives: 1355'],\n",
              " 'Specificity': [0.8261776581426649,\n",
              "  'True Negatives: 24554',\n",
              "  'False Positives: 5166']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N635uLfJwgr-"
      },
      "source": [
        "## Explore Spell Checking\n",
        "\n",
        "Note: After exploring a few different spell checkers, I ultimately decided not to continue testing spell check capability as a data preprocessing step prior to sentiment analysis with vader. \n",
        "\n",
        "This decision was made because, for each spell checker I tried, one of two things was true: \n",
        "\n",
        "1) The spell checker was capable of providing good results, but lacked the customization needed effectively implement in a pipeline for this project. An example of this is the neuspell BertChecker shown below. BertChecker was able to correct some spelling mistakes that most others could not, however when BertChecker is applied to a sentence, there is no way to limit what corrections are made. So while it was impressive in some areas, it made unacceptable mistakes in others such as manipulating hashtags. \n",
        "\n",
        "2) The spell checker did provide the needed flexibility to filter which corrections are made, however the method lacked accuracy and processing speed. An example of this is the Textblob spell checker. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP4mKaAXasaU"
      },
      "source": [
        "checker = BertChecker()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "6ad7679f32054d6ca7849e1dac3b4c8a",
            "02cf33be53c44fe8aa82e764ae9a3688",
            "8750c80029114a71b85c32fa20806eb9",
            "9b7307440c4a4241a78a76164f26d7a5",
            "77045328433e46aa9a79c27063b2607c",
            "c9eb48ea618643a784606bd06ed4737f",
            "40a53d98b2fd4064818c55a1528dc773",
            "4cdb609e5e3f40c4ae6c3bc857208b83",
            "3a5a3cb927844b498794818f3d489409",
            "a283f6c58e4c4c898da1743acecbf5b8",
            "5cb378e4a736458990395ea6c8a91e73",
            "5152e4f8b13b4bcea113c54735cd0762",
            "d72d1c86c4864db9b62dac2f67700838",
            "4a3ac44eb5194a649f5b2831de055165",
            "d6b52adc538f4873a0aa844fa4f1913e",
            "cad3643678144d57875d13dc46b65fd3"
          ]
        },
        "id": "tx8-LJrqjlKV",
        "outputId": "43161180-a6ad-4b06-d95f-b6c343590d60"
      },
      "source": [
        "checker.from_pretrained(\"/content/neuspell/data/checkpoints/subwordbert-probwordnoise\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/neuspell/data/checkpoints/subwordbert-probwordnoise created\n",
            "Pretrained model downloading start (may take few seconds to couple of minutes based on download speed) ...\n",
            "Pretrained model download success\n",
            "loading vocab from path:/content/neuspell/data/checkpoints/subwordbert-probwordnoise/vocab.pkl\n",
            "initializing model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ad7679f32054d6ca7849e1dac3b4c8a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a5a3cb927844b498794818f3d489409",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of parameters in the model: 185211810\n",
            "loading pretrained weights from path:/content/neuspell/data/checkpoints/subwordbert-probwordnoise\n",
            "Loading model params from checkpoint dir: /content/neuspell/data/checkpoints/subwordbert-probwordnoise\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "0c99b1d897614e1e9608050b8ddc9326",
            "0c8e6b128adf4c0996eaf9db63eb660e",
            "f4f6ce7fd6d44061bc994a91e9dcf0af",
            "1bbf1f7d2c3a4d74abca33261de8f0d1",
            "9a8fbdcae6e44266a1bcb57656bff773",
            "8a9a994bc92048ad9228f71b48174a9f",
            "58477cf0d21a4016a48fe5de7e043ddc",
            "0eb2874bd575414b940c382920808307",
            "c7277e530017419ead7058ccec7d264e",
            "b9fa9a3bab754e308136770ac1cfc479",
            "ff4d29b8920e4515b206e8b94beef58a",
            "121fdee9fe54400988e1303feb8c5798",
            "9ca1c0489ae0429ba73d134a16e2e006",
            "fb9f48ea6ab6446180d08a4046e097f5",
            "121e905e20524ffca1836b673ad37350",
            "f35cd4c14e8342a8af8b0ceed0e752c6",
            "0e0e9f83b164454182f740c4098f5681",
            "a82dd854978448a1818cde4e625ae5f4",
            "f89889d3b207437ba847c6eeae4b540c",
            "329738703b9d4c2ebfcdf3cdca85b054",
            "9935139196f046d682d0494cbd5042c6",
            "d92782fcd59b44b2b65dcda2c40f7a0f",
            "a508e1fb4b9143bab807fd36f71adc16",
            "d8168433c9a54deaa79df9286bf1b45f"
          ]
        },
        "id": "INMm_IsOcgB0",
        "outputId": "8fb8aa27-a315-4d00-fd11-0d6e4ec94c94"
      },
      "source": [
        "checker.correct(\"I luk foward to receving your reply\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c99b1d897614e1e9608050b8ddc9326",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7277e530017419ead7058ccec7d264e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e0e9f83b164454182f740c4098f5681",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I look forward to receiving your reply'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2awPrQ4kJ6z",
        "outputId": "03810818-637d-4036-d33b-81bc8e688d57"
      },
      "source": [
        "checker.correct_strings([\"I luk foward to receving your reply\", \"my frends has a bihday party tomrrow\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I look forward to receiving your reply',\n",
              " 'my friend has a birthday party tomorrow']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J118OOfNkb5l"
      },
      "source": [
        "tweet_list = list(tweet_df.loc[(tweet_df.index >= 1) & (tweet_df.index <= 5), 'tweet'].to_numpy())\n",
        "\n",
        "tweet_list_corrected = checker.correct_strings(tweet_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2xycRPllEBC",
        "outputId": "80d0b50b-be35-4c4a-cb7a-7291f138f3c1"
      },
      "source": [
        "corrected_vs_not = zip(tweet_list, tweet_list_corrected)\n",
        "for index, tweets in enumerate(corrected_vs_not):\n",
        "  original_tweet = tweets[0]\n",
        "  corrected_tweet = tweets[1]\n",
        "\n",
        "  print(\"Original Tweet: \", original_tweet)\n",
        "  print(\"Corrected Tweet: \", corrected_tweet)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Tweet:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n",
            "Corrected Tweet:  @ user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction . # run\n",
            "\n",
            "\n",
            "Original Tweet:  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\n",
            "Corrected Tweet:  @ user @ user thanks for # lift credit i can ' t use cause they don ' t offer wheelchair vans in pdx . # disappointed # getthanked\n",
            "\n",
            "\n",
            "Original Tweet:    bihday your majesty\n",
            "Corrected Tweet:  birthday your majesty\n",
            "\n",
            "\n",
            "Original Tweet:  #model   i love u take with u all the time in urð±!!! ððððð¦ð¦ð¦  \n",
            "Corrected Tweet:  # model i love u take with us all the time in urð± ! ! ! *\n",
            "\n",
            "\n",
            "Original Tweet:   factsguide: society now    #motivation\n",
            "Corrected Tweet:  factsguide : society now # motivation\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra8BhpE7u2GA"
      },
      "source": [
        "from textblob import TextBlob\n",
        "from textblob import Word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxNQ-6V2wHdI"
      },
      "source": [
        "def correct_tweet_spelling(tweet, spelling_confidence_threshold=0.75):\n",
        "  \n",
        "  tweet = tweet.strip()\n",
        "  tweet = re.sub(\" +\", \" \", tweet)\n",
        "\n",
        "  tweet_words = tweet.split(\" \")\n",
        "  processed_tweet = \"\"\n",
        "\n",
        "  for word in tweet_words:\n",
        "    if word.startswith('#') or ord(word[0]) > 127 or word.startswith(\"@\"): \n",
        "      processed_tweet = processed_tweet + word + \" \"\n",
        "    else: \n",
        "      word_obj = Word(word)\n",
        "      spelling_suggestions = word_obj.spellcheck()\n",
        "      top_suggestion_info = spelling_suggestions[0]\n",
        "      suggestion = top_suggestion_info[0]\n",
        "      confidence = top_suggestion_info[1]\n",
        "\n",
        "      if confidence >= spelling_confidence_threshold and suggestion != word: \n",
        "        processed_tweet = processed_tweet + suggestion + \" \"\n",
        "      else: \n",
        "        processed_tweet = processed_tweet + word + \" \"\n",
        "\n",
        "  processed_tweet = processed_tweet.strip()\n",
        "  processed_tweet = re.sub(\" +\", \" \", processed_tweet)\n",
        "\n",
        "  return processed_tweet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfo_JGSW2qLI"
      },
      "source": [
        "def perform_spelling_corrections(df, tweet_text_column='tweet', spelling_checked_column='Tweet_SpellChecked', spelling_confidence_threshold=0.75):\n",
        "\n",
        "  df[spelling_checked_column] = df[tweet_text_column].apply(correct_tweet_spelling, args=(spelling_confidence_threshold,))\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "080NWQVb1agV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487bf93e-74ab-4c87-df6c-0710d2ce702d"
      },
      "source": [
        "tweet_df = perform_spelling_corrections(tweet_df)\n",
        "spelling_correction = get_classification_metrics(tweet_df, tweet_text_column='tweet', verbose=True)\n",
        "\n",
        "spelling_correction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': [0.796101620674551,\n",
              "  'True Positives: 885',\n",
              "  'True Negatives: 24560',\n",
              "  'False Positives: 5160',\n",
              "  'False Negatives: 1357'],\n",
              " 'Precision': [0.14640198511166252,\n",
              "  'True Positives: 885',\n",
              "  'False Positives: 5160'],\n",
              " 'Sensitivity': [0.39473684210526316,\n",
              "  'True Positives: 885',\n",
              "  'False Negatives: 1357'],\n",
              " 'Specificity': [0.8263795423956931,\n",
              "  'True Negatives: 24560',\n",
              "  'False Positives: 5160']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfJpAcHVnFSU"
      },
      "source": [
        "spelling_correction_df = pd.DataFrame(tweet_df)\n",
        "\n",
        "spelling_correction_df.to_csv(path_or_buf=\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/text_blob_spelling_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0-dYxNszFos"
      },
      "source": [
        "# Function used to analyze the sentiment analyzer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMSMLC5x74XP"
      },
      "source": [
        "#---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# This function is used to perform multiple rounds of classification analysis using VADER. Results are returned as a dictionary, which can easily be\n",
        "# converted to a pandas DataFrame. This makes it very easy to compare how various threshold values and data cleaning decisions impact the accuracy of \n",
        "# classifications.\n",
        "#---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def analyze_vader(df, threshold_min=-0.5, threshold_max=0.5, num_thresholds=100, data_cleaning_dict=None, text_column='tweet', sentiment_analyzer=sentiment_analyzer,\n",
        "                  include_confusion_parameters=True): \n",
        "\n",
        "  threshold_values = list(np.linspace(start=threshold_min, stop=threshold_max, num=num_thresholds))\n",
        "\n",
        "  valid_keys = ['Remove_Twitter_Handles', 'Remove_Websites', 'Perform_Sentence_Tokenization']\n",
        "\n",
        "  if data_cleaning_dict is None or type(data_cleaning_dict) != dict or not all(keys in valid_keys for keys in data_cleaning_dict.keys()):\n",
        "    data_cleaning_dict = {'Remove_Twitter_Handles' : [True, False], \n",
        "                          'Remove_Websites' : [True, False], \n",
        "                          'Perform_Sentence_Tokenization' : [True, False]}\n",
        "\n",
        "  master_metrics = {'Accuracy' : [],\n",
        "                    'Sensitivity' : [],\n",
        "                    'Specificity' : [],\n",
        "                    'Precision' : [],\n",
        "                    'True_Positives' : [],\n",
        "                    'True_Negatives' : [],\n",
        "                    'False_Positives' : [],\n",
        "                    'False_Negatives' : [],\n",
        "                    'Removed_Twitter_Handles' : [], \n",
        "                    'Removed_Websites' : [],\n",
        "                    'Performed_Sentence_Tokenization' : [], \n",
        "                    'Decision_Threshold' : [] }\n",
        "\n",
        "  for twitter_handle_index, handle_parameter in enumerate(data_cleaning_dict['Remove_Twitter_Handles']):\n",
        "    for website_index, website_parameter in enumerate(data_cleaning_dict['Remove_Websites']): \n",
        "      for sent_token_index, sentence_token_param in enumerate(data_cleaning_dict['Perform_Sentence_Tokenization']):\n",
        "        for thresh_index, threshold_param in enumerate(threshold_values): \n",
        "\n",
        "          if handle_parameter == True:\n",
        "            df = remove_twitter_handles(df, tweet_text_column=text_column, no_handles_column='Tweet_Without_Handles')\n",
        "            text_column = 'Tweet_Without_Handles'\n",
        "          \n",
        "          if website_parameter == True: \n",
        "            df = remove_websites_from_tweets(df, tweet_text_column=text_column, no_website_column='Tweet_Without_Websites')\n",
        "            text_column = 'Tweet_Without_Websites'\n",
        "\n",
        "          metrics = get_classification_metrics(df, tweet_text_column=text_column, sentiment_analyzer=sentiment_analyzer, threshold=threshold_param,\n",
        "                                               sentence_level_analysis=sentence_token_param, include_confusion_params=include_confusion_parameters)\n",
        "\n",
        "          master_metrics['Accuracy'].append(metrics['Accuracy'])\n",
        "          master_metrics['Sensitivity'].append(metrics['Sensitivity'])\n",
        "          master_metrics['Specificity'].append(metrics['Specificity'])\n",
        "          master_metrics['Precision'].append(metrics['Precision'])\n",
        "          master_metrics['True_Positives'].append(metrics['True_Positives'])\n",
        "          master_metrics['True_Negatives'].append(metrics['True_Negatives'])\n",
        "          master_metrics['False_Positives'].append(metrics['False_Positives'])\n",
        "          master_metrics['False_Negatives'].append(metrics['False_Negatives'])\n",
        "          master_metrics['Removed_Twitter_Handles'].append(handle_parameter)\n",
        "          master_metrics['Removed_Websites'].append(website_parameter)\n",
        "          master_metrics['Performed_Sentence_Tokenization'].append(sentence_token_param)\n",
        "          master_metrics['Decision_Threshold'].append(threshold_param)\n",
        "\n",
        "  return master_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNTrtAQuBDU6"
      },
      "source": [
        "# This cell calls the function above to create a detailed analysis file that shows how changing the decision boundary and the use of data cleaning prior to analysis \n",
        "# will impact the effectiveness of using vaderSentiment as a hate speech classifier. This function takes a long time to run, therefore the code has been commented out\n",
        "# and the result of running this cell is simply imported from a csv file in the following cell.\n",
        "'''\n",
        "original_df = original_tweet_df.copy(deep=True)\n",
        "\n",
        "master_vader_metrics = analyze_vader(original_df, threshold_min=-0.99, threshold_max=0.99, num_thresholds=400)\n",
        "\n",
        "master_vader_df = pd.DataFrame(master_vader_metrics)\n",
        "\n",
        "filename=\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vaderSentiment_Analysis.csv\"\n",
        "\n",
        "master_vader_df.to_csv(path_or_buf=filename)\n",
        "\n",
        "master_vader_df.head()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "gly0USekzEpk",
        "outputId": "4593c778-9ab8-414a-c147-ccfa801239fd"
      },
      "source": [
        "# Reading in the analysis file created in the cell above. \n",
        "filename=\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vaderSentiment_Analysis.csv\"\n",
        "\n",
        "vader_analysis_df = pd.read_csv(filename, index_col=0)\n",
        "\n",
        "vader_analysis_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Precision</th>\n",
              "      <th>True_Positives</th>\n",
              "      <th>True_Negatives</th>\n",
              "      <th>False_Positives</th>\n",
              "      <th>False_Negatives</th>\n",
              "      <th>Removed_Twitter_Handles</th>\n",
              "      <th>Removed_Websites</th>\n",
              "      <th>Performed_Sentence_Tokenization</th>\n",
              "      <th>Decision_Threshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.929854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>29720</td>\n",
              "      <td>0</td>\n",
              "      <td>2242</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.929854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>29720</td>\n",
              "      <td>0</td>\n",
              "      <td>2242</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.985038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.929854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>29720</td>\n",
              "      <td>0</td>\n",
              "      <td>2242</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.980075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.929854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>29720</td>\n",
              "      <td>0</td>\n",
              "      <td>2242</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.975113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.929885</td>\n",
              "      <td>0.000446</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>29720</td>\n",
              "      <td>0</td>\n",
              "      <td>2241</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.970150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Sensitivity  ...  Performed_Sentence_Tokenization  Decision_Threshold\n",
              "0  0.929854     0.000000  ...                             True           -0.990000\n",
              "1  0.929854     0.000000  ...                             True           -0.985038\n",
              "2  0.929854     0.000000  ...                             True           -0.980075\n",
              "3  0.929854     0.000000  ...                             True           -0.975113\n",
              "4  0.929885     0.000446  ...                             True           -0.970150\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bXPcR7hhR2c"
      },
      "source": [
        "# Create output files for later analysis\n",
        "\n",
        "Create an output csv file that contains the tweet_df dataframe with the vader scores for each combination of the data cleaning decisions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8UzwTtkUfg6"
      },
      "source": [
        "# Output tweet_df dataframe with vader scores calculated using no data cleaning.\n",
        "\n",
        "# Commented out because the csv file has already been saved.\n",
        "'''\n",
        "tweet_no_data_cleaning_df = add_sentiment_score_columns(cleaned_tweet_df)\n",
        "\n",
        "filename=\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vader_no_data_cleaning.csv\"\n",
        "\n",
        "tweet_no_data_cleaning_df.to_csv(path_or_buf=filename, index=False)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_IhJVQaiO1H"
      },
      "source": [
        "# Output tweet_df dataframe with vader scores calculated using only twitter handle removal data cleaning.\n",
        "\n",
        "# Commented out because the csv file has already been saved.\n",
        "'''\n",
        "temp_df = cleaned_tweet_df.copy(deep=True)\n",
        "\n",
        "tweet_no_handles_df = remove_twitter_handles(temp_df)\n",
        "\n",
        "tweet_no_handles_df = add_sentiment_score_columns(df=tweet_no_handles_df, text_to_score_column='Tweet_Without_Handles')\n",
        "\n",
        "filename=\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vader_handles_removed.csv\"\n",
        "\n",
        "tweet_no_handles_df.to_csv(path_or_buf=filename, index=False)\n",
        "\n",
        "tweet_no_handles_df.head()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2mlY8R1ifpu"
      },
      "source": [
        "# Output tweet_df dataframe with vader scores calculated using only website removal data cleaning.\n",
        "\n",
        "# Commented out because the csv file has already been saved.\n",
        "'''\n",
        "temp_df = cleaned_tweet_df.copy(deep=True)\n",
        "\n",
        "tweet_no_website_df = remove_websites_from_tweets(temp_df)\n",
        "\n",
        "tweet_no_website_df = add_sentiment_score_columns(df=tweet_no_website_df, text_to_score_column='Tweet_Without_Websites')\n",
        "\n",
        "filename=\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vader_websites_removed.csv\"\n",
        "\n",
        "tweet_no_website_df.to_csv(path_or_buf=filename, index=False)\n",
        "\n",
        "tweet_no_website_df.head()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Hw2bBIXNN2"
      },
      "source": [
        "# Output tweet_df dataframe with vader scores calculated using only sentence level tokenization data cleaning.\n",
        "\n",
        "# Commented out because the csv file has already been saved.\n",
        "'''\n",
        "temp_df = cleaned_tweet_df.copy(deep=True)\n",
        "\n",
        "tweet_sentence_level_df = add_sentence_level_compound_score_column(df=temp_df, keep_subscores=True)\n",
        "\n",
        "filename=\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vader_sentence_level.csv\"\n",
        "\n",
        "tweet_sentence_level_df.to_csv(path_or_buf=filename, index=False)\n",
        "\n",
        "tweet_sentence_level_df.head()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-os4PojVa-v"
      },
      "source": [
        "# Commented out because these csv files have already been saved.\n",
        "'''\n",
        "# Output tweet_df dataframe with vader scores calculated using all data cleaning techniques (twitter handle removal, website removal, sentence level tokenization).\n",
        "\n",
        "tweet_all_preprocessing_df = remove_twitter_handles(cleaned_tweet_df, tweet_text_column='tweet', no_handles_column='Tweet_Without_Handles')\n",
        "\n",
        "tweet_all_preprocessing_df = remove_websites_from_tweets(tweet_all_preprocessing_df, tweet_text_column='Tweet_Without_Handles',\n",
        "                                                         no_website_column='No_Websites_Or_Handles')\n",
        "\n",
        "tweet_all_preprocessing_df = add_sentence_level_compound_score_column(df=tweet_all_preprocessing_df, tweet_text_column='No_Websites_Or_Handles', keep_subscores=True)\n",
        "\n",
        "filename=\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vader_full_preprocessing.csv\"\n",
        "\n",
        "tweet_all_preprocessing_df.to_csv(path_or_buf=filename, index=False)\n",
        "\n",
        "\n",
        "# Create a simplified version that has only what I need for modeling.\n",
        "tweet_all_preprocessing_df.drop(columns=['Tweet_Without_Handles', 'No_Websites_Or_Handles', 'Positive_Sentiment_Score',\n",
        "                                         'Negative_Sentiment_Score', 'Neutral_Sentiment_Score', 'Compound_Sentiment_Score'], inplace=True)\n",
        "\n",
        "# Shifting the compound score from (-1 to 1) to (0 to 2) because Naive bayes cannot take negative inputs.\n",
        "tweet_all_preprocessing_df['Sentence_Level_compound_Score'] = tweet_all_preprocessing_df['Sentence_Level_compound_Score'] + 1\n",
        "\n",
        "filename=\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vader_full_preprocessing_model.csv\"\n",
        "\n",
        "tweet_all_preprocessing_df.to_csv(path_or_buf=filename, index=False)\n",
        "\n",
        "tweet_all_preprocessing_df.head()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Generate_Soft_Voting_Ensemble_Predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgMX6s8cKPGZPdiNwQl2JG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BradenAnderson/Twitter-Sentiment-Analysis/blob/main/04_Generate_Soft_Voting_Ensemble_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu7750MHfB_l"
      },
      "source": [
        "## This notebook is used to generate soft voting ensembles for all combinations of the best models from the following types\n",
        "\n",
        "### 1. Naive Bayes\n",
        "### 2. Gradient Boosted Forest\n",
        "### 3. Multilayer Perceptron\n",
        "### 4. Logistic Regression\n",
        "\n",
        "All together 11 models are built and tested. The test results for each are output to their own csv files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUcHGrlqtvL4",
        "outputId": "365ba41a-16b8-4450-e8ad-97b0e0f19cc7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHkGlzKztd3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90502f33-8249-4ad9-903f-40752910b06a"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import itertools as it\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from mlxtend.classifier import EnsembleVoteClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "oMWPBlBJ3pBE",
        "outputId": "6417ed54-c01d-4e94-fb68-a15f99bee6f6"
      },
      "source": [
        "# Load the training data.\n",
        "filepath= \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vader_full_preprocessing_model_droppedlt3.csv\"\n",
        "\n",
        "train_tweet_df = pd.read_csv(filepath)\n",
        "\n",
        "train_tweet_df = train_tweet_df.loc[:, ['label', 'Clean_Tweet']]\n",
        "\n",
        "train_tweet_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Clean_Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>father dysfunctional significant selfish pron ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>thank #lyft credit use cause pron offer wheelc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday pron majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model love pron pron time pron happy love hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide society #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        Clean_Tweet\n",
              "0      0  father dysfunctional significant selfish pron ...\n",
              "1      0  thank #lyft credit use cause pron offer wheelc...\n",
              "2      0                                bihday pron majesty\n",
              "3      0  #model love pron pron time pron happy love hap...\n",
              "4      0                     factsguide society #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "BJxluy7Mtelt",
        "outputId": "1fd55e8b-7043-4cb2-d7fb-f21c0100f576"
      },
      "source": [
        "# Load the previously unseen test data.\n",
        "test_tweet_filepath = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/train_test_data/test_tweets_clean.csv\"\n",
        "\n",
        "test_tweet_df = pd.read_csv(test_tweet_filepath)\n",
        "\n",
        "test_tweet_df = test_tweet_df.loc[: , ['id', 'Clean_Tweet']]\n",
        "\n",
        "test_tweet_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Clean_Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>#white #supremacists want new #birds #movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe way heal pron #acne #altwaystoheal #healt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>hp curse child book reservation yes happy love...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday pron amazing hilarious #nephew eli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                        Clean_Tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964        #white #supremacists want new #birds #movie\n",
              "2  31965  safe way heal pron #acne #altwaystoheal #healt...\n",
              "3  31966  hp curse child book reservation yes happy love...\n",
              "4  31967  3rd #bihday pron amazing hilarious #nephew eli..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJh0_rxEddG4"
      },
      "source": [
        "# Grab the training data.\n",
        "X_train = train_tweet_df.loc[:, ['Clean_Tweet']]\n",
        "y_train = train_tweet_df.loc[:, 'label'].to_numpy().ravel()\n",
        "\n",
        "# Grab the previously unseen test data.\n",
        "X_test = test_tweet_df.loc[:, ['Clean_Tweet']]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKEYTczIZxqY"
      },
      "source": [
        "# Locations where I saved the pickle files for the best performing models.\n",
        "best_nb_filename = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/pickle_gridsearch/naive_bayes_ros_gs2.pkl\"\n",
        "best_gbf_filename = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/pickle_gridsearch/bf_ros_gs1.pkl\"\n",
        "best_lr_filename = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/pickle_gridsearch/lr_ros_gs1.pkl\"\n",
        "best_mlp_filename = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/pickle_gridsearch/mlp_gs1_sm.pkl\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5ETTLI1gwJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430f12d7-2e8f-48c9-a135-6749d17dd76f"
      },
      "source": [
        "# Load the .pkl gridsearch result files for the best performing model of each type.\n",
        "with open(best_nb_filename, 'rb') as file:\n",
        "  best_nb_model = pickle.load(file)\n",
        "\n",
        "with open(best_lr_filename, 'rb') as file:\n",
        "  best_lr_model = pickle.load(file)\n",
        "\n",
        "with open(best_gbf_filename, 'rb') as file:\n",
        "  best_gbf_model = pickle.load(file)\n",
        "\n",
        "with open(best_mlp_filename, 'rb') as file: \n",
        "  best_mlp_model = pickle.load(file)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc_KaVM5XkCk"
      },
      "source": [
        "# The top estimators for each model type.\n",
        "best_estimators = [('nb', best_nb_model.best_estimator_),\n",
        "                   ('lr', best_lr_model.best_estimator_),\n",
        "                   ('gbf', best_gbf_model.best_estimator_),\n",
        "                   ('mlp', best_mlp_model.best_estimator_)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgri1bSEbmLN"
      },
      "source": [
        "# This function automates creating soft voting ensembles for the top models from the following categories:\n",
        "# Naive Bayes, Logistic Regression, Gradient Boosted Random Forest, and Multilayer Perceptron.\n",
        "# The predictions made by each ensemble are saved in a .csv format with a descriptive file name.\n",
        "#\n",
        "def ensemble_all_combinations_of_best_models(best_model_list, X_train, y_train, X_test, test_tweet_df): \n",
        "\n",
        "  base_filename = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/04_generate_predictions/automated_predictions/soft_voting/soft_\"\n",
        "\n",
        "  num_best_models = len(best_model_list)\n",
        "\n",
        "  combination_sizes = list(range(1, num_best_models + 1))\n",
        "\n",
        "  for size in combination_sizes:\n",
        "\n",
        "    print(\"---------creating ensembles of size \", size, \"---------\")\n",
        "\n",
        "    # All combinations of models of a given size\n",
        "    best_estimator_combinations = it.combinations(best_model_list, size)\n",
        "\n",
        "    for combo_num, combination in enumerate(best_estimator_combinations):\n",
        "\n",
        "      models = []\n",
        "\n",
        "      specific_filename = base_filename + \"ensembleSize_\" + str(size) + \"_\" + \"combo_\" + str(combo_num + 1) + \"_\"\n",
        "\n",
        "      # Build the list containing this combination of models. Finish building the specific file name.\n",
        "      for model_num, model in enumerate(combination):\n",
        "\n",
        "        models.append(model) \n",
        "\n",
        "        model_name = model[0]\n",
        "\n",
        "        specific_filename = specific_filename + str(model_name) + \"_\"\n",
        "\n",
        "      # Create the ensemble classifier using this combination of best models.\n",
        "      ensemble_vote = VotingClassifier(estimators = models, voting='soft')\n",
        "\n",
        "      print(\"fitting: \", specific_filename)\n",
        "      # Fit the ensemble on the training data\n",
        "      ensemble_vote.fit(X_train, y_train)\n",
        "      print(\"fit complete!\\n\")\n",
        "\n",
        "      print(\"Making predictions.\")\n",
        "      # Use the ensemble to make predictions on the test data.\n",
        "      predictions = ensemble_vote.predict(X_test)\n",
        "      \n",
        "      # Save the predictions in a data frame.\n",
        "      predictions_df = test_tweet_df.loc[: , ['id']].copy(deep=True)\n",
        "\n",
        "      print(\"Finishing predictions dataframe.\")\n",
        "      predictions_df['label'] = predictions\n",
        "\n",
        "      # Finish the filename by adding the .csv extension\n",
        "      specific_filename = specific_filename + \".csv\"\n",
        "\n",
        "      print(\"Saving predictions file to:\", specific_filename)\n",
        "      # Save the predictions made by this ensemble out to a .csv file.\n",
        "      predictions_df.to_csv(path_or_buf=specific_filename, index=False)\n",
        "      print(\"\")\n",
        "\n",
        "      # Make sure the file name is reset for the next round.\n",
        "      specific_filename = base_filename \n",
        "\n",
        "  return"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ-3IEKjiNEk"
      },
      "source": [
        "# Calling this function will take all combinations of the best models that are capable of soft voting ensembling (MLP, LogReg, Naive Bayes, and Boosted Forest)\n",
        "# and will fit and then test these ensembles on unseen data. The test results for each combination are output to a .csv file with a descriptive name. \n",
        "ensemble_all_combinations_of_best_models(best_estimators, X_train, y_train, X_test, test_tweet_df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Gradient_Boosted_Forest_Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIZ6cFHBEaD/D4cjuCfnO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BradenAnderson/Twitter-Sentiment-Analysis/blob/main/04_Gradient_Boosted_Forest_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYeM263-g1pZ"
      },
      "source": [
        "## This notebook contains the code to perform hyperparameter tuning on Gradient Boosted Random Forest Models. \n",
        "\n",
        "## Displaying and reviewing the search results is done in the 04_Modeling_Analysis notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad_IVrRGvIWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9388b3a6-12c8-42f8-9ab6-2eb80f76ca1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REesbUR8uslM"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split, cross_validate, cross_val_predict\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, SCORERS, multilabel_confusion_matrix, make_scorer, roc_curve, roc_auc_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a9ubCp-xyt1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "1f2c5aca-f61c-462c-e422-346c9e1e0074"
      },
      "source": [
        "filepath= \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vader_full_preprocessing_model_droppedlt3.csv\"\n",
        "\n",
        "tweet_df = pd.read_csv(filepath)\n",
        "\n",
        "tweet_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>Clean_Tweet</th>\n",
              "      <th>Sentence_Level_pos_Score</th>\n",
              "      <th>Sentence_Level_neg_Score</th>\n",
              "      <th>Sentence_Level_neu_Score</th>\n",
              "      <th>Sentence_Level_compound_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father dysfunctional significant selfish pron ...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.211</td>\n",
              "      <td>0.789</td>\n",
              "      <td>0.58520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thank #lyft credit use cause pron offer wheelc...</td>\n",
              "      <td>0.157</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.843</td>\n",
              "      <td>1.33525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday pron majesty</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model love pron pron time pron happy love hap...</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.806</td>\n",
              "      <td>1.36245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society #motivation</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ... Sentence_Level_compound_Score\n",
              "0      0  ...                       0.58520\n",
              "1      0  ...                       1.33525\n",
              "2      0  ...                       1.00000\n",
              "3      0  ...                       1.36245\n",
              "4      0  ...                       1.00000\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EdOpqTEvuvw"
      },
      "source": [
        "# Regex pattern to split the tweets into tokens.\n",
        "pattern=r'\\b\\w\\w+\\b|(?<!\\w)#\\w+'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DunMEF6ycnNZ"
      },
      "source": [
        "'''\n",
        "X = tweet_df.loc[:, ['Clean_Tweet']]\n",
        "y = tweet_df.loc[:, 'label'].to_numpy().ravel()\n",
        "\n",
        "preprocess = ColumnTransformer(transformers=[(\"Tfidf_Vect\", TfidfVectorizer(token_pattern=pattern), 'Clean_Tweet')],\n",
        "                               remainder='passthrough')\n",
        "\n",
        "tree_num_distribution = [100, 200, 300, 600, 1000, 1200]\n",
        "max_depth = [-1, 5, 9]\n",
        "\n",
        "model_pipeline = Pipeline([(\"textPreprocess\", preprocess),\n",
        "                           (\"boosted_trees\", LGBMClassifier())])\n",
        "\n",
        "parameter_grid = [{'textPreprocess__Tfidf_Vect__analyzer' : ['word'],\n",
        "                   'textPreprocess__Tfidf_Vect__stop_words' : ['english'],\n",
        "                   'textPreprocess__Tfidf_Vect__ngram_range' : [(1,1), (1,2)],\n",
        "                   'textPreprocess__Tfidf_Vect__max_df' : [0.9, 1.0], \n",
        "                   'textPreprocess__Tfidf_Vect__min_df' : [1, 5],\n",
        "                   'boosted_trees__n_estimators' : tree_num_distribution, \n",
        "                   'boosted_trees__max_depth' : max_depth,\n",
        "                   'boosted_trees__subsample' : [0.7, 1.0],                    # Enable random selection of training cases (rows).\n",
        "                   'boosted_trees__colsample_bytree' : [0.8, 1.0],             # Percentage of features to randomly consider at each split.\n",
        "                   'boosted_trees__learning_rate' : [0.01, 0.05]}]\n",
        "\n",
        "score_types = {'f1_score' : make_scorer(f1_score), 'sensitivity' : make_scorer(recall_score), 'specificity' : make_scorer(recall_score, pos_label=0),\n",
        "               'AUC_ROC' : 'roc_auc', 'ROC_AUC_Score' : make_scorer(roc_auc_score), 'accuracy' : 'accuracy', 'precision' : make_scorer(precision_score)}\n",
        "\n",
        "gs = GridSearchCV(estimator=model_pipeline, param_grid=parameter_grid, scoring=score_types, refit='f1_score', n_jobs=-1)\n",
        "\n",
        "gs.fit(X,y)\n",
        "\n",
        "PATH = '/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/pickle_gridsearch/bf_gs1.pkl'\n",
        "\n",
        "with open(PATH, 'wb') as file:\n",
        "  pickle.dump(gs, file)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_imIxmbmsfm0"
      },
      "source": [
        "# Imblearn pipeline is the same as sklearn pipeline with added functionality to support over sampling.\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgfS-2gyrzy0"
      },
      "source": [
        "'''\n",
        "X = tweet_df.loc[:, ['Clean_Tweet']]\n",
        "y = tweet_df.loc[:, 'label'].to_numpy().ravel()\n",
        "\n",
        "preprocess = ColumnTransformer(transformers=[(\"Tfidf_Vect\", TfidfVectorizer(token_pattern=pattern), 'Clean_Tweet')],\n",
        "                               remainder='passthrough')\n",
        "\n",
        "random_os = RandomOverSampler()\n",
        "\n",
        "tree_num_distribution = [1150, 1200, 1250]\n",
        "max_depth = [-1]\n",
        "\n",
        "model_pipeline = Pipeline([(\"textPreprocess\", preprocess),\n",
        "                           ('overSampler', random_os),\n",
        "                           (\"boosted_trees\", LGBMClassifier())])\n",
        "\n",
        "parameter_grid = [{'textPreprocess__Tfidf_Vect__analyzer' : ['word'],\n",
        "                   'textPreprocess__Tfidf_Vect__stop_words' : ['english'],\n",
        "                   'textPreprocess__Tfidf_Vect__ngram_range' : [(1,1)],\n",
        "                   'textPreprocess__Tfidf_Vect__max_df' : [0.95, 1.0], \n",
        "                   'textPreprocess__Tfidf_Vect__min_df' : [1, 2],\n",
        "                   'boosted_trees__n_estimators' : tree_num_distribution, \n",
        "                   'boosted_trees__max_depth' : max_depth,\n",
        "                   'boosted_trees__subsample' : [0.65, 0.7, 0.75],                    # Enable random selection of training cases (rows).\n",
        "                   'boosted_trees__colsample_bytree' : [0.75, 0.8, 0.85],             # Percentage of features to randomly consider at each split.\n",
        "                   'boosted_trees__learning_rate' : [0.04, 0.05, 0.06],\n",
        "                   'overSampler__sampling_strategy' : ['auto', 0.4, 0.6]}]\n",
        "\n",
        "score_types = {'f1_score' : make_scorer(f1_score), 'sensitivity' : make_scorer(recall_score), 'specificity' : make_scorer(recall_score, pos_label=0),\n",
        "               'AUC_ROC' : 'roc_auc', 'ROC_AUC_Score' : make_scorer(roc_auc_score), 'accuracy' : 'accuracy', 'precision' : make_scorer(precision_score)}\n",
        "\n",
        "gs = GridSearchCV(estimator=model_pipeline, param_grid=parameter_grid, scoring=score_types, refit='f1_score', n_jobs=-1)\n",
        "\n",
        "gs.fit(X,y)\n",
        "\n",
        "PATH = '/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/pickle_gridsearch/bf_ros_gs1.pkl'\n",
        "\n",
        "with open(PATH, 'wb') as file:\n",
        "  pickle.dump(gs, file)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7LU8sja6cp-"
      },
      "source": [
        "'''\n",
        "X = tweet_df.loc[:, ['Clean_Tweet']]\n",
        "y = tweet_df.loc[:, 'label'].to_numpy().ravel()\n",
        "\n",
        "preprocess = ColumnTransformer(transformers=[(\"Tfidf_Vect\", TfidfVectorizer(token_pattern=pattern), 'Clean_Tweet')],\n",
        "                               remainder='passthrough')\n",
        "\n",
        "random_os = RandomOverSampler()\n",
        "\n",
        "tree_num_distribution = [1150, 1200, 1250]\n",
        "max_depth = [-1]\n",
        "\n",
        "model_pipeline = Pipeline([(\"textPreprocess\", preprocess),\n",
        "                           ('overSampler', random_os),\n",
        "                           (\"boosted_trees\", LGBMClassifier())])\n",
        "\n",
        "parameter_grid = [{'textPreprocess__Tfidf_Vect__analyzer' : ['word'],\n",
        "                   'textPreprocess__Tfidf_Vect__stop_words' : ['english'],\n",
        "                   'textPreprocess__Tfidf_Vect__ngram_range' : [(1,1)],\n",
        "                   'textPreprocess__Tfidf_Vect__max_df' : [0.95], \n",
        "                   'textPreprocess__Tfidf_Vect__min_df' : [1],\n",
        "                   'boosted_trees__n_estimators' : tree_num_distribution, \n",
        "                   'boosted_trees__max_depth' : max_depth,\n",
        "                   'boosted_trees__subsample' : [0.65, 0.7, 0.75],                    # Enable random selection of training cases (rows).\n",
        "                   'boosted_trees__colsample_bytree' : [0.75, 0.8, 0.85],             # Percentage of features to randomly consider at each split.\n",
        "                   'boosted_trees__learning_rate' : [0.04, 0.05, 0.06],\n",
        "                   'overSampler__sampling_strategy' : ['auto', 0.4, 0.6]}]\n",
        "\n",
        "score_types = {'f1_score' : make_scorer(f1_score), 'sensitivity' : make_scorer(recall_score), 'specificity' : make_scorer(recall_score, pos_label=0),\n",
        "               'AUC_ROC' : 'roc_auc', 'ROC_AUC_Score' : make_scorer(roc_auc_score), 'accuracy' : 'accuracy', 'precision' : make_scorer(precision_score)}\n",
        "\n",
        "gs = GridSearchCV(estimator=model_pipeline, param_grid=parameter_grid, scoring=score_types, refit='f1_score', n_jobs=1)\n",
        "\n",
        "gs.fit(X,y)\n",
        "\n",
        "PATH = '/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/pickle_gridsearch/bf_ros_gs1.pkl'\n",
        "\n",
        "with open(PATH, 'wb') as file:\n",
        "  pickle.dump(gs, file)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
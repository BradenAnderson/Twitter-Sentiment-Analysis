{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_fastText.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCY8ZLXpqzN3hOLz6g912h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BradenAnderson/Twitter-Sentiment-Analysis/blob/main/05_fastText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCpX_JrjR2Oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d76aa57-ce7f-4f71-ef4d-00d40809b141"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffHDFkU4R8uX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400a4160-2dfd-47e3-bf08-3409ae138014"
      },
      "source": [
        "# Clone the fastText github repository\n",
        "! git clone https://github.com/facebookresearch/fastText.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3854, done.\u001b[K\n",
            "remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n",
            "Receiving objects: 100% (3854/3854), 8.22 MiB | 15.17 MiB/s, done.\n",
            "Resolving deltas: 100% (2417/2417), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpMNp5e2R9rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa353af1-7ae4-474d-885f-739737a10790"
      },
      "source": [
        "# Install the in a local folder in my google drive.\n",
        "! pip install /content/fastText"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (54.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3085775 sha256=9cfddf039f0cdb76c7b7d9f19b3aa605e1c3e3e75792e4f00082d7cc061b7b06\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0prnoz44/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "856XgItSR-9l"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import fasttext\n",
        "from fasttext.FastText import load_model\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split, cross_validate, cross_val_predict\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, SCORERS, multilabel_confusion_matrix, make_scorer, roc_curve, roc_auc_score, f1_score\n",
        "\n",
        "pd.set_option('display.max_rows', 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHrJSyvMSzVc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0fd9a6f0-9e49-43a3-e39c-0a757a5afd2c"
      },
      "source": [
        "# Read in the tweet data set.\n",
        "filepath= \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/vader_full_preprocessing_model.csv\"\n",
        "\n",
        "tweet_df = pd.read_csv(filepath)\n",
        "\n",
        "# Make a copy of the tweet dataset that only includes clean tweets and the target labels.\n",
        "fastText_df = tweet_df.loc[:, ['label', 'Clean_Tweet']].copy(deep=True)\n",
        "\n",
        "ft_df = fastText_df.copy(deep=True)\n",
        "\n",
        "fastText_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Clean_Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>father dysfunctional significant selfish pron ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>thank #lyft credit use cause pron offer wheelc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday pron majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model love pron pron time pron happy love hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide society #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        Clean_Tweet\n",
              "0      0  father dysfunctional significant selfish pron ...\n",
              "1      0  thank #lyft credit use cause pron offer wheelc...\n",
              "2      0                                bihday pron majesty\n",
              "3      0  #model love pron pron time pron happy love hap...\n",
              "4      0                     factsguide society #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHCtnfW5StEa"
      },
      "source": [
        "# Setting up train and test files for supervised learning with fastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNR2R3HbXG8U"
      },
      "source": [
        "# Filepath to where I am saving the fastText formatted supervised learning file with all of the tweet data.\n",
        "all_data_filepath = r'/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/all_data.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "323Zk_DjWJbB"
      },
      "source": [
        "# Save locations where we will store the training and testing data files once they are created.\n",
        "# If someone else ever uses this notebook, this should help make it easier so they have less links to change.\n",
        "\n",
        "train_data_filepath = r'/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/train_data.txt'\n",
        "test_data_filepath = r'/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/test_data.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQVQ_xgkTDXM"
      },
      "source": [
        "# Function used to format labels the way fastText needs them for supervised learning. \n",
        "def format_label(current_label):\n",
        "  prefix = \"__label__\"\n",
        "  formatted_label = prefix + str(current_label)\n",
        "  return formatted_label "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3uOCA7kTEAy"
      },
      "source": [
        "# Change the label column from simple 0's and 1's to __label__0 or __label__1\n",
        "fastText_df['fastText_Label'] = fastText_df['label'].apply(format_label)\n",
        "\n",
        "# make the label and tweet text one big string (e.g. __label__0tweet_text_here) - this is how fastText needs it for training.\n",
        "fastText_df['labeled_tweets'] = fastText_df['fastText_Label'] + fastText_df['Clean_Tweet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWbBvrfkXWKN"
      },
      "source": [
        "# Save a file containing all of the data. We will need this to retrain our final model once the optimal hyperparameters are found. \n",
        "np.savetxt(all_data_filepath, fastText_df['labeled_tweets'], fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRPC19l1Tx5p"
      },
      "source": [
        "# Create a copy of the dataframe with the correctly formatted column.\n",
        "fastText_formatted_df = fastText_df.copy(deep=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QySHUNMQT1Ie"
      },
      "source": [
        "# Remove all the columns that fastText won't need.\n",
        "fastText_formatted_df.drop(columns=['label', 'Clean_Tweet', 'fastText_Label'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2ChWxhoT6Z4"
      },
      "source": [
        "# Use scikit-learns train_test_split to split the properly formatted labeled data into a training and testing set.\n",
        "X = fastText_df['labeled_tweets'].to_numpy()\n",
        "y = fastText_df['label'].to_numpy()\n",
        "\n",
        "# Note: Since fastText trains on data where the label and data are one big string, the X_train and X_test are all we need for training\n",
        "# and testing respectively. The y_train and y_test are just going to be thrown away.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXG5hNU4UnKp"
      },
      "source": [
        "# Save X_train and X_test into training and testing data frames.\n",
        "training_df = pd.DataFrame(X_train, columns=['labeled_tweets'])\n",
        "testing_df = pd.DataFrame(X_test, columns=['labeled_tweets'])\n",
        "\n",
        "# Write the contents of the training and testing dataframes out to a text file, which can later be read by fastText.\n",
        "np.savetxt(train_data_filepath, training_df['labeled_tweets'], fmt='%s')\n",
        "np.savetxt(test_data_filepath, testing_df['labeled_tweets'], fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AM1mHWAU4Yt"
      },
      "source": [
        "# Explore using fastText as a classifier (supervised learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mDzNU0Wh7ZT"
      },
      "source": [
        "# The fastText test function returns the precision and recall classification metrics. \n",
        "# This function uses precision and recall to calculate the F1-score. \n",
        "def calculate_f1_score(model_results):\n",
        "  num_samples, precision, recall = model_results\n",
        "  f1_score = 2 * ( (precision  * recall)/(precision + recall))\n",
        "  return f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYwsRuFjU-Mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ab9847-07d7-42c5-b875-af06ed53cbc7"
      },
      "source": [
        "# Location where we will save the trained model.\n",
        "first_model_filepath = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/ft_first_model.bin\"\n",
        "\n",
        "# Commented out because the trained model has been saved, therefore training does not need to be repeated each time. (Commented out because training has been accomplished).\n",
        "# first_model = fasttext.train_supervised(input=train_data_filepath, epoch=25)\n",
        "\n",
        "# Save the model so we don't have to retrain the next time we run this notebook. (Commented out because training/saving has been accomplished).\n",
        "# first_model.save_model(first_model_filepath)\n",
        "\n",
        "# Load the trained model.\n",
        "first_model = load_model(first_model_filepath)\n",
        "\n",
        "# Test the model on the training data file.\n",
        "first_model_test_result = first_model.test(test_data_filepath)\n",
        "\n",
        "first_model_test_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6184, 0.30206985769728334, 0.30206985769728334)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Le0R_LitN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0132bd-51dd-4a4c-a4df-b18a7f431112"
      },
      "source": [
        "# Calculate the f1 score for the first model.\n",
        "first_model_f1 = calculate_f1_score(first_model_test_result)\n",
        "first_model_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30206985769728334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxtOshRFXLz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4527885d-132b-4293-89bd-418c838fa02b"
      },
      "source": [
        "# Creating a second model, limit the training time to 10 minutes (1200 seconds), and use the autotuneValidate parameter to automatically tune the models\n",
        "# hyperparameters using the test file.\n",
        "\n",
        "# Location to save the trained model.\n",
        "second_model_filepath = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/autoTuned_model.bin\"\n",
        "\n",
        "# Training the model and auto tuning hyperparameters. (Commented out because training has been accomplished).\n",
        "# tuned_model = fasttext.train_supervised(input=train_data_filepath, autotuneValidationFile=test_data_filepath, autotuneDuration=1200)\n",
        "\n",
        "# Save the trained model so we don't have to repeat training next time we run the notebook. (Commented out because training/saving has been accomplished).\n",
        "# tuned_model.save_model(second_model_filepath)\n",
        "\n",
        "# Loading the trained model.\n",
        "tuned_model = load_model(second_model_filepath)\n",
        "\n",
        "# Testing the model on the test .txt file.\n",
        "tuned_model_test_results = tuned_model.test(test_data_filepath)\n",
        "\n",
        "tuned_model_test_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6160, 0.1775974025974026, 0.1775974025974026)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu0rB0IOi1OC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465fb9c1-1566-41da-8db1-496416c99352"
      },
      "source": [
        "# Calculate the f1 score for the auto tuned model.\n",
        "# Note: Limiting the autotune time to 10 minutes decreased performance as compared to the manually selected hyperparameters used by our first model.\n",
        "tuned_model_f1 = calculate_f1_score(tuned_model_test_results)\n",
        "tuned_model_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1775974025974026"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdeou_fwZZY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a9f26c-5bb5-46a3-d992-ac4f18d96906"
      },
      "source": [
        "# Creating another model, increasing the training time by a lot (30k seconds = 8.333 hours) and again autoTuning the hyper parameters.\n",
        "\n",
        "# Location to save the trained model.\n",
        "long_train_filepath = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/autoTuned_longTrain_model.bin\"\n",
        "\n",
        "# Training the model.(Commented out because training has been accomplished).\n",
        "# long_tune_model = fasttext.train_supervised(input=train_data_filepath, autotuneValidationFile=test_data_filepath, autotuneDuration=30000)\n",
        "\n",
        "# Save the trained model so we don't have to repeat training next time we run the notebook. (Commented out because training/saving has been accomplished).\n",
        "# long_tune_model.save_model(long_train_filepath)\n",
        "\n",
        "# Load the trained model.\n",
        "long_tune_model = load_model(long_train_filepath)\n",
        "\n",
        "# Test the model using the test set.\n",
        "long_tune_test_results = long_tune_model.test(test_data_filepath)\n",
        "\n",
        "# Letting fastText autoTune the hyperparameters for 8+ hours greatly increased our classification metrics. \n",
        "long_tune_test_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6184, 0.8279430789133247, 0.8279430789133247)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "441dLB9uOqsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a56af4-f44c-47fe-b1e4-0c90aab895a9"
      },
      "source": [
        "# Creating another model, increasing the training even more (82.8k seconds = 23 hours) and again autoTuning the hyper parameters.\n",
        "\n",
        "# Location to save the trained model.\n",
        "very_long_train_filepath = \"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/23hr_model.bin\"\n",
        "\n",
        "# Training the model. (commented out because training has already been accomplished).\n",
        "# very_long_model = fasttext.train_supervised(input=train_data_filepath, autotuneValidationFile=test_data_filepath, autotuneDuration=82800)\n",
        "\n",
        "# Save the trained model so we don't have to repeat training next time we run the notebook. (commented out because saving has already been accomplished).\n",
        "# very_long_model.save_model(very_long_train_filepath)\n",
        "\n",
        "# Load the trained model.\n",
        "long_model = load_model(very_long_train_filepath)\n",
        "\n",
        "# Test the model using the test set.\n",
        "very_long_trained_model_test_results = long_model.test(test_data_filepath)\n",
        "\n",
        "# Allowing the additional training time (23 hours compared to 8.33) did result in further improvements to the precision and recall.\n",
        "very_long_trained_model_test_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6176, 0.8492551813471503, 0.8492551813471503)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxoLuLTPapy_"
      },
      "source": [
        "# Explore using fastText to create vector representations of words (unsupervised learning).\n",
        "\n",
        "Note: The word vector representations created by fastText can be used as inputs to a supervised learning classifier, I will explore this concept in the next section. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYVm8Ci0a3ia"
      },
      "source": [
        "# Location to save the text file that is properly formatted for fastText unsupervised learning (creating word vector representations).\n",
        "unlabeled_tweet_filepath = r'/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/unlabeled_data.txt'\n",
        "\n",
        "# Location to save the file of learned word vector representations\n",
        "word_vector_model_filepath = r\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/unsupervised_model.bin\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EecfIrybcupu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "51561b14-1f2c-4ba0-b76c-09bc0f4ce504"
      },
      "source": [
        "# Dataframe that has a column of the clean (unlabeled) tweet text.\n",
        "ft_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Clean_Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>father dysfunctional significant selfish pron ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>thank #lyft credit use cause pron offer wheelc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday pron majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model love pron pron time pron happy love hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide society #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        Clean_Tweet\n",
              "0      0  father dysfunctional significant selfish pron ...\n",
              "1      0  thank #lyft credit use cause pron offer wheelc...\n",
              "2      0                                bihday pron majesty\n",
              "3      0  #model love pron pron time pron happy love hap...\n",
              "4      0                     factsguide society #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAH2BAerbWmg"
      },
      "source": [
        "# Save the unlabeled tweet data to a text file that fastText can read and create word vectors from.\n",
        "np.savetxt(unlabeled_tweet_filepath, ft_df['Clean_Tweet'], fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9qWsz2Ubvz5"
      },
      "source": [
        "# Use a skipgram model to create word vector representations of every word in the tweets.\n",
        "# Note: This does not need to be commented out because it runs fast! (i.e. fastText :) ) \n",
        "unsupervised_model = fasttext.train_unsupervised(unlabeled_tweet_filepath, model='skipgram')\n",
        "\n",
        "# Save the learned word vector representations.\n",
        "unsupervised_model.save_model(word_vector_model_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6Qrfl1JdFFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11074be-e447-4e15-d6ef-daf6224d622a"
      },
      "source": [
        "# Print a list of words that fastText learned word vectors for.\n",
        "print(unsupervised_model.words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['</s>', 'pron', 'happy', 'love', 'day', 'significant', 'amp', '#love', 'good', 'time', 'sad', 'like', 'today', 'flirt', 'new', 'joy', '#positive', 'want', 'people', 'life', 'thank', 'come', 'look', 'need', 'father', 'wait', 'feel', 'work', '2', 'bihday', '#smile', '#healthy', 'week', 'know', 'think', 'find', 'cool', 'great', 'year', 'bull', '#thankful', 'confident', 'thing', 'summer', '#fun', 'thankful', 'watch', 'tomorrow', '3', '#life', 'friend', 'right', 'live', 'funny', 'world', 'morning', '1', '#i', '#summer', 'night', '#model', '#cute', '#affirmation', 'excitement', 'weekend', '#blog', 'girl', 'man', '#fathersday', 'play', '#me', '4', 'let', 'leave', 'angry', 'home', 'oh', 'finally', 'celebrate', 'family', 'silly', 'game', 'god', 'tonight', '#gold', 'gt', '#silver', 'friday', '#altwaystoheal', 'old', 'dad', '#beautiful', 'guy', 'ready', 'bear', '#bihday', '#family', 'power', '#music', 'joke', 'sta', 'little', 'other', '#selfie', '#friends', 'wish', '#weekend', 'try', '#forex', 'miss', '#day', 'stop', 'place', 'tweet', 's', 'laugh', 'help', 'climb', 'pay', 'strong', 'hope', 'follow', 'bad', '#happiness', 'smile', '#orlando', 'lose', 'city', 'amazing', 'happen', 'use', 'beautiful', 'big', 'race', 'woman', '#friday', 'sunday', 'pray', 'real', 'defeat', 'positive', 'end', '#instagood', 'trump', 'head', 'disappointed', 'book', '5', 'polar', 'hate', 'fun', 'alcohol', 'hour', 'celebration', 'white', 'black', 'win', 'long', 'change', 'school', 'believe', '#blessed', 'video', 'direct', 'news', 'kid', 'free', 'month', 'enjoy', '$', 'pain', 'w', '%', 'nice', '2016', 'music', 'lot', 'sex', 'food', 'hear', 'lt', '#peace', 'attack', 'n', 'meet', 'orlando', 'excited', 'grief', 'tell', 'buy', '#girl', 'hea', '#sun', 'soon', 'dominate', 'check', 'bawl', 'read', 'fuck', 'face', 'word', 'kill', 'away', 'surprise', '#trump', 'd', 'yes', 'loud', 'approval', '#motivation', 'forward', 'listen', 'team', 'post', '#grateful', 'r', 'tear', '#quote', '#photooftheday', 'baby', '#sunday', 'vacation', 'break', 'stay', '#followme', 'talk', '#follow', '#work', 'true', 'happiness', 'child', 'racist', '#fashion', 'person', '10', 'yeah', 'bing', 'moment', 'bong', 'fan', 'late', '#a', '#dog', 'boy', '6', 'hard', '#funny', 'mean', 'job', 'saturday', 'run', 'open', '7', '#tbt', 'song', 'travel', 'sleep', 'die', '#cool', '#travel', 'reach', 'buffalo', 'house', 'order', '#euro2016', '#home', 'lovely', 'awesome', 'ticket', 'gorilla', 'pa', 'thought', 'mad', '#dad', '#beach', 'kind', 'care', 'gun', 'country', 'wow', 'fear', 'shoot', 'story', 'mind', '#happy', 'twitter', 'gift', 'x', 'environment', '#food', 'agree', '#enjoy', 'high', 'america', 'lead', 'turn', 'dream', '#holiday', '#hot', 'bring', 'conference', 'season', 'embarassed', '#depression', 'monday', 'simulator', 'adapt', '0', 'accept', 'shit', 'congratulation', '#girls', 'beach', '#heale', 'june', 'tip', 'simulation', 'arrive', 'poetry', 'sun', '#father', 'mom', 'sick', 'body', '#inspiration', 'walk', 'money', 'send', 'finish', '#joy', 'learn', 'join', 'hot', 'super', 'close', 'ask', 'movie', 'matter', 'wake', 'act', 'gay', 'remember', 'cold', 'hey', 'set', '#fitness', 'share', 'dog', 'dead', 'shock', 'till', 'comment', 'ppl', '#politics', '9', 'success', 'reason', 'perfect', '#quotes', 'wonderful', 'rest', 'update', 'present', 'forget', 'eat', '#pay', 'delete', '#fathers', 'pic', 'young', 'cause', 'tag', 'fact', 'determination', 'visit', 'culture', 'fathers', '#success', 'proud', 'choose', '#rip', 'photo', 'far', 'complete', 'cry', 'point', '#saturday', '#allahsoil', 'shooting', '#retweet', 'minute', '8', '#prayfororlando', 'sign', 'event', 'feeling', 'sarcastic', 'vote', 'spend', '#sexy', 'wedding', 'ass', 'hug', '#free', 'sure', 'actually', '#proud', 'hat', 'victim', 'useful', 't', '#wedding', 'dance', 'fall', 'pretty', 'begin', '#beauty', 'bless', 'aww', 'picture', 'wrong', 'hardcore', '#lifestyle', 'obama', '#live', '#hair', 'anymore', 'holiday', '#health', '#2016', 'bed', '1st', '#deletetweets', 'stae', '#nature', 'development', 'plan', 'date', 'hair', '#baby', 'car', 'speak', 'impoant', '12', 'couple', 'state', 'p', 'grow', 'hold', '50', 'fathersday', 'early', '#liberal', 'son', 'hit', '#like', '#friend', '#tgif', 'yesterday', '30', '#picoftheday', 'release', 'lie', 'y', 'follower', 'favorite', 'ago', 'understand', 'daily', '#libtard', '#relax', 'm', 'episode', '20', 'special', 'racism', 'guess', 'libtard', '#photography', '#goodmorning', 'business', '#good', 'trip', 'suppo', 'easy', 'relief', 'human', '#mindset', '#today', 'okay', 'star', 'peace', '16', '#sjw', 'forever', 'mood', 'app', '#black', '#london', 'fly', '#new', '#healing', 'h', 'na', 'medium', 'sorry', '#morning', 'able', 'target', 'group', 'organization', '#sad', 'ok', '#amazing', 'later', 'pass', '15', 'evening', '#awesome', '#flowers', 'mindset', 'crazy', 'vs', 'cat', 'luck', 'delicious', 'dear', 'death', 'bird', '#cantwait', 'cute', 'gbp', 'frustration', 'save', 'low', 'way', 'e', 'realize', '#nervous', 'damn', 'achievement', '#lgbt', 'control', 'problem', 'annoy', 'drink', 'survive', 'message', 'everyday', 'welcome', 'simple', '#gay', 'final', '#shop', '#anxiety', 'decide', 'yay', 'count', '#miami', 'wednesday', 'p.m.', 'parent', 'fight', 'bit', 'eye', 'single', 'bitch', 'stand', 'f', 'despite', 'half', '#monday', 'light', 'customer', 'lady', '#dance', '#cat', 'park', 'add', 'royal', 'shop', 'thursday', 'truth', '#people', 'better', 'create', 'hello', '11', 'sit', 'tired', 'yo', 'president', 'write', 'prayer', 'launch', 'phone', 'july', '#usa', 'idea', 'safe', 'maybe', 'source', '100', 'list', 'porn', '#truth', 'tv', 'support', 'treat', 'history', 'card', '#depressed', 'stuff', '#smiles', 'fucking', 'vicinity', 'view', 'line', 'student', 'hill', 'course', '#affirmations', '#thankyou', '#sunshine', 'club', '#photo', 'sweet', '#nude', 'class', 'htt', 'step', '#boy', 'stupid', 'experience', 'service', '#lol', 'selfie', 'pick', 'afternoon', '#kids', 'mountain', 'london', 'small', 'issue', 'self', 'rain', 'irritation', 'truly', 'color', 'wonder', 'disappoint', 'daughter', 'voice', '#hate', '06', 'officially', 'account', '#world', 'allow', 'awe', 'mother', 'soul', 'daddy', 'luxury', 'consider', '#america', '#porn', 'brother', 'expect', 'shake', 'film', 'task', 'kick', '2nd', '#lawofattraction', 'police', 'rip', '#like4like', 'sister', '#lighttherapy', 'room', 'lunch', 'sale', 'instagram', 'test', 'vine', 'deserve', 'wealth', '#style', '#thursday', 'ahead', 'health', 'sound', 'sport', 'community', 'question', '#coffee', '3d', 'football', '#instalike', '#alone', '#blue', 'past', 'age', 'hell', 'wear', 'anniversary', 'conce', 'chase', 'announce', 'tuesday', 'law', 'bored', '#udtapunjab', 'usd', 'ride', '#gym', 'lucky', 'l', 'catch', 'different', '#sunny', 'nervous', '#hope', 'green', '#young', 'instead', '#education', 'choice', 'ignore', '00', 'continue', '#horny', 'second', '#blur', 'return', 'folk', 'murder', '#slut', '#naughty', 'receive', '#nice', '#kinky', 'water', '#shy', 'flight', 'mass', 'uk', 'product', '#orlandoshooting', 'negative', 'fast', 'vast', '#leadership', 'sell', 'glad', '#vacation', 'fire', 'cut', 'yr', 'social', 'secret', 'rooster', 'expanse', 'wife', 'stomp', 'facebook', 'drop', '#nasty', '#laugh', 'coffee', '#xxx', '#instamood', '#pretty', '#brexit', 'nude', 'bag', 'v', 'drive', '2017', 'rock', 'office', 'notice', 'flag', 'cover', 'client', 'page', 'american', 'oil', 'official', 'cheer', 'red', 'freedom', 'violence', 'answer', 'series', '#nyc', 'future', 'beauty', '#dream', '#couple', 'hu', 'concern', 'sexy', 'teen', 'poor', 'blue', '#inshot', 'local', '#wet', 'award', 'beat', 'husband', '#instagram', 'bday', 'campaign', 'exciting', 'quote', 'pride', '#ripchristina', 'pre', 'fill', '#news', 'member', 'respect', 'block', 'pack', 'embarasse', '#time', 'stick', 'deal', '24', 'camp', 'fantastic', 'political', 'offer', '#oitnb', 'memory', 'hand', 'street', 'national', 'co', 'blame', 'road', 'blog', '#instadaily', 'sho', '#celebrate', 'seriously', 'tragedy', '#best', 'busy', 'york', 'prove', 'fail', '13', 'action', 'leader', '99', '#sea', 'sense', 'war', 'literally', 'christmas', 'available', '#night', 'store', 'train', '#friendship', 'woh', 'animal', 'flower', 'meeting', 'absolutely', 'mr', '#mood', 'hero', 'waste', 'design', 'huge', 'tune', 'previous', 'land', '#god', '#lonely', 'dark', 'awkward', 'reality', 'online', 'probably', 'xx', '#sweet', '#snapshot', '#dads', 'case', '#newyork', 'number', '#change', 'trust', 'gym', 'link', '#e32016', 'result', 'session', 'inside', 'project', 'everybody', 'hi', 'goal', 'heal', '#ff', 'clean', '#melancholy', 'lover', 'album', 'attention', 'ice', '#nofilter', 'hillary', 'record', '#obama', '#makeup', 'haha', '#inspirational', 'internet', 'england', 'college', '17', 'staff', 'chance', 'bc', 'box', 'loss', 'town', '#tired', 'euro', 'female', '#dj', 'key', '#us', 'donald', 'email', 'naked', 'nation', '#design', 'excite', 'especially', 'dinner', '#yay', '#japan', 'leakage', 'garden', '#yoga', 'deep', 'stage', '#vegan', 'million', '#dogs', '#lovelife', '#tech', '#goodvibes', 'terrorist', 'player', 'ocean', '#fit', 'benefit', '#women', 'training', '#white', 'americans', 'stas', '#social', 'click', 'dress', 'beer', 'claim', '#wednesday', 'near', 'queen', '#hu', '#cake', 'g', 'build', 'india', 'relax', 'totally', 'til', '#disney', 'nail', '#melancholymusic', '#crazy', 'piece', 'ball', 'tour', 'boyfriend', 'shoe', '#thanks', 'todays', 'worry', 'staed', 'door', '#chill', '#june', '#florida', '#gif', 'brand', 'board', '#blogger', 'da', 'anti', 'throw', '#yummy', '#running', 'touch', 'foot', 'favourite', '#loveit', '#money', '#youtube', '#hea', 'pussy', '14', 'pop', 'at', 'content', 'liberal', 'hang', '#heabroken', '#man', 'suck', 'teach', 'price', '#business', 'exactly', 'skeptical', 'public', 'review', 'lack', '#share', 'role', '#behappy', 'min', 'nearly', 'match', 'appreciate', 'pizza', 'eah', 'level', '#sunset', 'sunshine', '#fridayfeeling', 'usa', 'term', 'fake', 'healthy', '#workout', 'condemn', 'company', 'fine', '#essentialoils', 'generation', 'ex', '#boyfriend', 'girlfriend', 'mistake', '18', '#run', '#snapchat', '#positivity', 'alive', 'track', 'material', 'ponder', 'dude', '#igers', 'florida', 'tho', 'august', 'ness', 'intelligent', 'islam', 'website', '#ootd', 'speech', '#you', '#tampa', 'dory', 'muslim', 'lord', 'politician', 'type', 'snapchat', '#maga', 'chill', 'affect', '#tuesday', 'web', '#l4l', '#why', 'remain', 'possible', '19', '#sick', 'entire', 'round', '#foodporn', 'straight', 'gorgeous', 'idiot', 'mention', 'bro', '#video', 'decision', '#eur', 'roll', 'tool', 'retweet', 'weather', 'christina', '#smiling', '#gratitude', 'suppoer', 'double', 'festival', '#fresh', 'bar', 'space', 'shame', '#pathetic', 'air', 'note', '25', 'st', '#analytics', 'disney', '#idwp', 'adventure', 'outside', 'system', '#animals', 'market', 'definitely', 'de', 'youtube', '#broken', 'breakfast', 'sadly', 'bike', 'ramadan', '#goodtimes', 'la', 'fix', 'church', 'judge', 'suppose', 'rule', 'pathetic', 'france', '#shopping', '#daughter', '#daddy', 'press', 'base', 'register', 'suppoers', '#actor', '#rain', '#ripchristinagrimmie', '#my', '#bigot', '#future', 'apparently', 'horrible', 'wild', 'prepare', '#puppy', 'study', 'lyric', '#hungry', '#lover', 'bet', '#babies', 'vibe', 'wall', 'scene', '#gop', 'gain', 'irriration', 'shift', '#woman', 'google', 'confuse', 'south', 'sky', '#cry', 'hopefully', 'youth', '#quoteoftheday', 'candidate', 'current', '#flower', '#calgary', 'force', '#uk', 'perform', '#twitter', '#wine', '#single', '#gamedev', 'fresh', '#loved', 'religion', '70', 'stream', 'mum', '#repost', 'emotion', '#pray', '#anime', 'sea', 'shi', '#blm', 'cross', 'attend', '#humpday', '#blonde', '#pink', 'sing', 'destroy', 'simply', 'profile', '#jobs', '#heal', 'text', 'cuz', '#f4f', '#green', 'cup', 'pig', '#breakfast', '#ramadan', '#positivevibes', '#energy', 'promote', 'download', '#loveislove', '#hispanic', 'value', '#moment', 'brilliant', '#temple', 'rise', '#photos', 'response', '#media', '#school', 'lebron', 'style', '#tragic', 'winner', '#australia', '#red', 'english', 'include', 'hotel', '#wedde', 'exam', '#goodday', 'site', 'struggle', '#findingdory', 'broker', '#garden', 'shut', 'cream', 'shout', '#goodnight', 'collection', 'hatred', '#cats', 'tea', 'boss', 'left', '#team', '000', 'sunny', 'powerful', 'opinion', 'imagine', '#punjab', 'actor', '#lunch', '#foodie', 'reveal', 'risk', 'involve', '#astrologer', '#bouncingbaby', 'germany', '#sikh', 'mischief', '#colombia', 'fab', '#nbafinal', 'purchase', '#sky', 'orange', 'seek', '#forever', 'bill', 'clear', 'performance', 'fo', 'en', 'muslims', '#pain', 'weak', '#entrepreneur', '#great', 'clearly', '#squad', 'niggas', 'ya', '#omg', 'coach', '#wow', 'king', '#trip', 'raise', 'male', '#men', 'michael', 'best', 'nba', '#staup', '#son', 'calm', 'protest', 'countdown', 'blow', '#game', 'voter', '21', 'aist', 'warm', 'injure', 'smart', '#teambts', 'mark', '#paris', 'nightclub', 'cock', 'journey', 'area', 'enemy', 'senseless', '#bride', 'graduate', '#lovely', '#bjp', '#true', 'congrat', 'longer', 'shopping', 'interview', 'burn', '#spos', '#memes', 'weight', 'login', '#wso', 'cake', 'vandalise', 'charge', 'shine', '#yum', 'adult', 'politic', 'sir', 'john', '#strong', '#confused', 'finger', '#handmade', 'focus', 'serve', '#inlove', 'lil', 'opening', '#the', 'relationship', '#boricua', 'search', '#children', '#relationship', '#e3', 'spread', '#mom', 'tragic', 'apple', 'robe', '#edm', 'university', 'wine', 'challenge', 'remove', 'grateful', 'govt', '#flag', 'spos', 'quick', '#guns', '#blackandwhite', '#movie', '#neverump', 'west', '90', '#football', '#faith', '#likeforlike', 'trend', 'factory', '#apple', '#yes', 'seat', 'glass', 'middle', '#no', 'cancel', 'row', 'singe', '#drawing', '#christinagrimmie', 'puppy', 'pm', 'bout', 'completely', 'slow', 'protect', '#body', '#indiedev', 'non', 'print', 'afraid', 'paner', 'wakeup', 'diet', '#drinks', 'route', 'bottle', 'jo', 'cavs', '#emotional', 'graduation', 'rally', '#dinner', '#gift', 'nigga', '3rd', 'form', 'centre', 'society', 'troll', 'excellent', 'promise', '#festival', 'ring', 'ugly', '#malevote', '#child', 'teacher', 'arm', 'remind', 'sma', '#comedy', 'clothe', 'reaction', '#pulse', 'grimmie', '#up', 'crime', '#goals', 'unfounately', 'gop', 'host', 'channel', 'ruin', 'steal', 'band', '#california', 'marriage', '#misogyny', '#be', 'policy', 'bank', '#lucky', '#pool', '#weightloss', 'practice', '#familytime', 'alligator', 'rape', '#help', 'total', 'moon', '#memories', 'figure', '#united', 'worker', 'cow', 'evil', 'anger', 'abt', '#flagday2016', 'terrible', '#celebration', '#amaze', '#mindfulness', 'deliver', 'le', '#bigotry', 'friendship', 'title', '#scared', 'statement', 'hrs', 'push', '#pet', '#loa', 'marry', 'driver', '#gamer', 'difficult', 'inspire', 'cou', 'disgusting', 'chick', 'san', 'government', 'makeup', 'fat', '#pride', 'stock', 'ha', 'shall', 'ban', 'brown', 'blonde', 'brexit', 'ignorance', '#la', '#fitfam', 'hide', 'election', '#nbafinals', 'feed', 'excuse', 'united', 'repo', '#sleep', '#usd', '#bihdaygirl', '#perfect', 'screen', 'etc', '#wednesdaywisdom', '#wellness', '#emiratis', 'islamic', 'somebody', '#finger', 'j', '#race', '#apps', 'brain', 'rate', 'tree', 'vegas', '#ocean', '#passion', 'pretend', 'disagree', 'ugh', '#web', 'disgust', '#feeling', 'materia', 'heaven', 'blood', 'chat', '#humor', 'yoga', 'version', 'september', 'attempt', 'provide', 'innocent', '#beer', '#kitty', 'terrorism', '#seashepherd', '#wtf', 'process', 'ukhx', 'lake', '#dreams', '#goal', 'reply', 'plus', 'balance', 'int', '#aist', 'program', '#wisdom', '#smh', '#exercise', 'sunset', 'bye', 'drug', 'doubt', 'confirm', 'workshop', 'shot', '#lifeisgood', '#university', 'confused', 'cox', '#mad', 'ad', 'major', '#spain', 'pool', 'bright', 'thousand', '#amwriting', 'feature', '#believe', '#play', 'kingdom', 'delay', '#win', 'situation', '#instapic', '#ibiza', 'speaker', 'lesson', 'bus', '#throwback', '#days', 'attitude', 'pink', '#hatred', 'explain', 'rich', 'manage', 'ally', '#asian', 'option', 'image', 'invite', '#adventure', '#nursery', 'loose', '#all', 'quality', 'dangerous', '#respect', 'island', '#organic', 'legend', 'complain', 'remedy', 'request', 'blessed', '#ready', 'rhymes', '#bestfriend', 'meal', 'station', 'wing', '#sohappy', 'aicle', 'expectation', 'size', '#vegas', 'mile', '#eng', 'workout', 'clinton', 'large', 'anne', '#crying', '80', 'massive', 'successful', '#swag', '#s', 'bestie', 'texas', 'xxx', 'shooter', 'tough', 'babe', '#eyes', 'industry', 'advice', '#blacklivesmatter', '#holidays', 'essential', 'league', 'info', 'lgbt', 'stress', 'scream', '#peaceful', '#toptags', '#freedom', 'index', 'snow', '#france', '#feliz', 'exist', 'upset', '40', '#together', 'fuher', 'states', 'shepherd', 'officer', 'assault', 'bernie', 'blessing', '#feminismmuktbharat', '#feminismisterrorism', 'agenda', '#feminismiscancer', 'interest', 'a.m.', 'talented', '#fridayfeele', 'strength', '#feelings', '#meditation', '#americans', 'leak', 'express', 'studio', '#countdown', '#hello', '22', 'theatre', '#vsco', '#tcot', 'education', '#antiracism', 'connect', 'suppoe', '#car', '#so', '#fail', 'fave', 'noh', 'nyc', 'common', 'warrior', 'copy', 'restaurant', 'dj', '#rock', 'drag', '#loveyou', '#chicago', '#inspired', 'fair', '#finally', 'cook', '#sister', 'creative', 'fish', 'eve', 'delivery', 'chair', '#book', 'radio', 'pro', 'airpo', 'edit', '#misogynist', '#icecream', 'angel', 'thanks', '#face', 'chicken', 'bae', 'paint', 'wh', 'ground', 'root', 'watermelon', '60', 'sis', 'schedule', 'purpose', 'cop', 'humanity', 'crack', 'isis', 'basis', 'yep', 'grand', 'gig', '#altright', 'wales', 'netflix', 'increase', 'fit', '#animal', 'forecast', '#mylove', 'main', '#sundayfunday', 'detail', 'ma', 'career', '#successful', '#delicious', '#disappointed', 'degree', 'conservative', 'normal', 'princess', '#conce', 'skin', '#moments', 'master', '#bff', 'worried', 'spot', '#film', '#view', 'jesus', 'talent', 'mate', 'limit', 'draw', '#emo', 'bridge', 'score', 'proof', '#notmypresident', 'hater', 'fellow', '#drink', 'pleasure', 'bore', '#bestfriends', '#israel', 'describe', '#sleepy', 'republican', 'rainbow', 'theme', 'global', '#ireland', '#history', 'shower', 'commercial', 'taste', '#adorable', 'incredible', 'venue', 'stone', 'jpy', 'papa', 'fav', 'kit', 'cost', '#anniversary', '#aap', 'terror', 'david', '200', '#suicide', 'defend', 'mess', 'science', '49', 'hospital', '#1gabba', 'prize', 'progress', '#lost', 'europe', '#russia', 'james', 'load', 'honest', 'gold', 'asian', '#canada', '#mondaymotivation', 'pure', '#tragedy', 'energy', 'famous', '27', 'fabulous', 'mini', 'hoe', '#sorry', '#poetry', '#sex', 'dare', 'pull', 'log', '#luxury', '#india', '#little', '#gbp', '#training', 'mail', 'easily', 'table', 'crew', 'trail', '#frustrated', 'surprised', 'humble', 'reject', 'storm', '#instacool', 'nominee', 'impression', '#childhood', 'silent', '#tagsforlikes', 'snap', 'datum', 'battle', '#bored', '#xoxo', '#boys', 'dick', 'boat', 'production', '#upset', 'fox', '#ukraine', 'fam', '#look', '#jobsearch', '#socialmedia', '#spring', 'insane', 'spain', '#handsome', 'mirror', 'punjab', '#england', '#indiegamedev', 'honor', 'mouth', '#diy', 'remark', 'owner', 'whe', '#greece', 'magic', '#loser', '#marriage', 'african', 'fed', 'spin', 'russia', 'kevin', '#vk', 'tattoo', 'twice', '#equality', 'natural', '#eid', 'trouble', '#walk', '#king', 'drunk', '#bogota', 'materi', '#sunnyday', 'ali', 'kiss', '#vibes', '#summeime', '#shoes', 'bully', '#yellow', 'plane', 'fool', '#scary', 'dr', '#tears', '#bloggers', 'amazed', 'correct', '#weather', 'period', '#eat', '#romance', '#color', '#2016in4words', '#yolo', 'christian', 'ill', 'praise', 'warn', 'hungry', 'represent', 'hahaha', 'cousin', 'faith', 'hole', 'colour', 'friendly', '26', '#illustration', 'model', 'lip', 'difference', 'address', 'wa', '#vine', 'reminder', '#next', 'fitness', '#tb', '#joytrain', '#winter', 'bbc', 'heat', 'blast', 'stunning', 'april', 'respond', 'spring', '#annoyed', 'discuss', 'carl', 'truck', 'credit', 'carry', 'effo', 'scared', '#germany', 'mode', '#latepost', 'see', 'escape', 'knowledge', 'planning', 'condolence', 'building', 'basic', 'classic', 'anton', '#islam', 'swear', 'chapter', 'location', 'jump', 'com', '#ps4', 'smell', 'holy', 'repeat', '#doplants', '#therapy', 'suffer', '#beard', 'window', '#teen', 'sight', 'research', '#groom', 'cucumber', '#hype', 'typical', 'downtown', 'trash', '#bday', 'mp', '#glasses', '#2', '#china', 'ki', 'library', '#bird', '#motivated', '#southafrica', 'ceain', '35', 'network', 'michelle', 'mix', 'lately', '#netflix', 'decade', '#lasvegas', '#friyay', '#tokyo', 'electronic', 'upload', '#bless', 'hire', '#dress', '#homophobic', 'tiny', '#periscope', 'growth', 'epic', 'grade', '#iphone', '#amen', 'ignorant', 'plant', 'solve', 'aim', 'appear', '#barcelona', '#bliss', 'upcoming', '#sundaymorning', 'commit', 'path', 'fully', 'international', '#clouds', '#writer', 'village', 'avoid', '#birds', 'suit', 'actual', 'arrest', '#living', 'lay', 'trade', 'highlight', 'precious', '#singer', 'impact', 'recognize', 'buddy', '#poem', '#weak', '#gaming', '#very', '#muslim', 'george', 'currently', 'quiet', '#song', '#reading', 'disease', 'honestly', 'trending', '#stress', 'reflection', 'herbal', '#resources', '#raw', '#feel', '#grace', '#twitch', 'paris', 'cinema', 'mama', 'tony', 'bs', 'weird', 'gator', 'cast', 'suspect', '11th', 'horrific', 'military', '28', '#city', '#facebook', '#now', '#antonyelchin', 'usually', 'spo', 'whilst', '#feelinggood', '#2017', 'salad', '#nationalbestfriendsday', 'smoke', 'bomb', 'rat', 'argument', 'comfo', '#story', '500', 'pet', '#pic', '#nowplaying', 'alarm', 'goodbye', 'times', '#thailand', '#animation', 'planet', 'woohoo', 'mexican', '#cnn', '#bf', 'false', 'mobile', 'lee', 'crap', '#legend', 'leg', '#show', '#vscocam', '#detoxdiet', 'cheap', 'expose', 'incredibly', 'bitcoin', 'kitchen', 'piss', 'rid', 'sneak', 'definition', 'dumb', '#to', 'realise', '#guitar', '#mylife', 'binge', 'children', 'gear', 'pulse', '#feelgood', 'recent', 'bloody', 'skill', '#brother', 'earn', '#diet', 'mall', '#youtuber', 'dis', 'code', '#season4', 'demand', 'ireland', '#magnettherapy', '#acne', 'radical', '#rainbow', 'singer', 'stranger', 'cleveland', '95', 'east', '#feminism', 'boot', '#gorgeous', '#colorful', '#kid', 'contract', 'ft', '#nba', '#puntohost', '40404', 'laughter', 'hype', 'abuse', 'field', 'piano', 'debate', '#studio', '#save', 'boom', '#cheers', 'jealous', '#loving', '#kkk', 'poem', 'annual', 'iphone', 'enter', 'hashtag', 'soo', 'anybody', '#self', 'chocolate', 'independent', '#follow4follow', 'poll', '#pussy', '#scotland', '#edinburgh', 'plenty', 'equal', '#author', '#boycott', 'silence', 'center', 'basketball', '#thursdaythoughts', 'knock', 'bother', '#liar', '#gameofthrones', '#bestseller', '#weddingplanning', 'horse', 'pair', '#loveisland', '#roadtrip', 'computer', '#and', 'emotional', '#creative', '#books', 'karen', 'e3', 'milk', 'cheat', 'engage', 'presentation', 'sirf', '#safe', 'lazy', '#weird', 'retail', '#carlpaladino', '#bad', '#silly', '#instahappy', 'grace', 'inspiration', '#nightout', 'recover', 'jan', '#caturday', '#goodmood', 'chip', 'loser', 'retweete', '#jewelry', 'indian', 'weapon', 'giant', '#nerd', '#when', 'interesting', '#calm', '2015', '#picture', 'handle', 'podcast', '#mind', 'asshole', 'await', '#natural', 'relevant', 'spark', '#wwdc2016', 'rainy', 'poster', 'consumer', '#hillary', 'presidential', 'crowd', '#anger', 'citizen', 'refuse', 'discover', '#spiritual', '#italy', '#aud', 'cuddle', 'winter', 'security', '#big', '#terrorism', 'improve', 'sadness', '#girlfriend', 'announcement', 'bride', 'original', 'flat', 'employee', 'las', '#turkey', '#light', 'hump', '#write', 'toddler', 'movement', 'mental', 'massacre', 'hubby', '#queen', 'joe', 'director', 'tom', 'paladino', 'reunite', '#republican', '#brunette', 'nowadays', '#we', '#bestoftheday', '#resist', 'bitter', '#sushi', 'distance', 'con', 'majority', 'lifestyle', 'ashiq', 'lonely', '#losangeles', 'dat', '#cold', 'bind', '#toronto', 'contact', '2b', 'nigeria', '#laughter', 'jews', 'beginning', '#tattoo', '#mentalhealth', '#fml', 'suspend', 'kitty', 'odd', 'roof', 'congrats', '#inspire', '#joke', '#lovemylife', 'closer', '#brighton', 'embrace', 'lock', 'doctor', '#loveyourself', '#water', 'regard', '#urdu', 'absolute', '#comingsoon', 'racial', 'sub', 'frm', 'yelchin', '#heabreaking', 'sms', 'apa', '#unhappy', '#chocolate', 'hv', 'bastard', 'eu', '29', '#golf', 'introduce', 'professional', '#orlandonightclubshooting', 'jim', 'bio', '#evening', 'fashion', '#bbq', 'jersey', '#putinschoice', 'rn', 'curry', 'position', '#shame', 'regret', 'toy', 'guest', 'vendor', 'belong', 'language', 'competition', 'mat', '#unleashyourjoy', 'summit', '#buffalo', '#lifecoach', '#summer2016', 'expensive', 'comic', 'stephen', '#hiphop', 'trailer', '#bbuk', '#graduation', 'yoy', '#amarinder', 'extremely', 'peeps', 'wrap', 'character', 'xd', '#selflove', '#content', '#instagay', 'alt', 'swimming', 'rose', 'bee', 'extra', '#madrid', 'grab', '#anxious', '#piano', '05', '#pizza', '#masterkeyexperience', 'paul', 'achieve', 'playlist', 'excit', 'lookin', '#married', 'reso', 'obviously', 'access', 'coz', 'revolution', '#swim', 'killer', 'wave', 'golf', '#cycling', 'laptop', '#week', 'awake', 'denial', '#balance', '#dark', 'assume', 'anxiety', 'fl', 'keshi', 'pageant', 'swim', '#kindness', '#zen', 'recovery', 'ed', '#justice', 'mexico', '#theatre', '#geek', 'suppos', 'interested', 'hockey', 'criminal', '#confident', 'genuine', '#teamsuperjunior', 'hathaway', 'possibility', 'barely', '#cedm', 'zone', '#horror', 'slowly', 'wood', 'cad', 'bubble', '#park', 'outfit', 'apply', 'fuel', 'admit', '#guys', 'bliss', 'luv', '#prayersfororlando', '45', '#out', 'guide', '#coldplaywembley', 'blind', '#prayers', 'desire', 'incident', 'bts', '#not', 'allah', '#wasi', '#cleveland', '#house', 'repoer', 'badly', 'gang', 'th', '#suicidal', '#go', '#letsgo', '#mohsin', '#faraz', '#cavs', 'suicide', '#galib', 'nature', '#iqbal', 'factsguide', '#your', 'general', '#goodlife', '#xenophobia', '#longhair', 'japan', '#venusexchange', '#fascism', 'africa', 'example', 'routine', '#wetter', '#warnung', '5th', '#hollywood', '#starbucks', 'relate', 'measure', '#schwandorfchwandorf', 'california', '#feele', '#gewitter', '#potus', '#tv', '#really', 'prevent', '#donaldtrump', 'november', '#mexico', 'manchester', 'matt', 'reverse', 'neighbor', 'menu', 'obamas', '2008', 'brave', 'golden', '#memorie', 'worship', 'bay', 'crash', 'floor', 'ka', '#fear', '#emotions', '#trending', '#customer', '#make', 'athlete', 'treasure', 'british', '#peppa', '#pop', 'italy', '#hard', 'standard', 'tale', '#relaxing', 'funeral', 'paper', '#theresistance', '#bestie', '#np', 'starkes', '#spo', 'bunch', 'yea', 'letter', 'argue', 'recipe', 'random', '#educationfest', '#wetterwarnung', '#dwd', 'flip', 'likely', 'chicago', '#painting', 'democracy', 'liar', '#shocked', 'ji', '#magic', '#niece', '#bed', 'sigh', 'genocide', 'polarisation', 'heabroken', 'ah', 'independence', 'nose', 'referendum', '#wonderful', 'scum', 'poland', 'dig', '#europe', 'wise', '#orangeisthenewblack', '#namaste', 'bite', '#unbelievable', 'sa', '#soul', 'potato', '#kiss', '#well', '#church', 'willing', '#epic', '#stay', 'witness', '#emotion', '#uselections2016', 'ny', 'complaint', 'dragon', '#bikini', 'bih', 'bob', 'shark', '#dancing', 'stadium', '#kitten', 'funday', '#dayoff', 'anal', 'lawyer', '#vip', '#outdoors', 'manager', 'hardly', '#vlicobs', 'oppounity', 'appreciation', '#texas', 'frank', '#tonight', '#swimming', 'demo', 'wisdom', '#with', 'monkey', 'systemic', '#science', 'violent', 'minority', '#kejriwal', '#vintage', '#gemini', 'dust', 'sexual', 'quit', '#strength', '#it', '#first', 'direction', 'butt', '#poland', 'inc', 'breath', '#soundcloud', 'sandy', 'effect', 'fault', '#msnbc', 'information', 'cm', 'button', 'bbq', '#meme', '48', 'pump', '#dead', 'thrive', 'unhappy', 'fuhere', '#guy', 'depression', 'grandpa', '#ugh', 'speed', 'bounce', 'tick', 'williams', '#photographer', '#teeth', 'finale', 'screw', 'traffic', '#game7', '#berlin', 'quickly', 'mo', 'potential', 'hugs', 'congress', '4th', 'react', '#wakeup', '#in', 'filter', '#satisfied', 'union', '#pakistan', 'adam', 'afford', 'machine', '#f1', 'b4', '9th', '#boston', '#babygirl', 'awful', '#lovinglife', 'defense', 'responsible', '#pougal', 'illegal', 'valley', '#hug', 'childhood', '23', 'usual', '#saysomething', 'beg', 'girls', '#tshi', 'yummy', '#rich', 'gender', 'clue', 'hall', 'lo', 'range', 'educate', '#fundraising', 'wheel', 'mil', 'sponsor', '#real', 'drama', 'draft', '#wife', '#writing', 'activity', 'looki', 'label', '#fruit', 'gb', 'sacrifice', '#review', 'whoop', 'tie', '#newmusic', 'tupac', '#mentalillness', 'pas', '1000', 'exercise', 'korea', 'xbox', 'passion', 'japanese', 'lemon', 'insult', 'sake', 'rage', '#kpop', '#euros2016', 'nasty', 'confidence', 'farmer', 'disgrace', 'hs', 'dc', 'married', '#porait', '#nutrition', '#webcam', 'endorse', '#journey', '#fascist', '6th', '14th', '21st', '2day', 'grad', 'aka', 'di', '#atherapy', '#piggie', 'declare', '#dogsofinstagram', '#thinkbigsundaywithmarsha', 'teaser', 'lmfao', 'personal', 'censorship', '#herbalremedies', 'coldplay', 'mid', '#musictherapy', 'primary', 'domestic', 'advocate', '#relaxed', 'shade', 'musical', '#nike', '#super', '#instamoment', 'william', '#followers', '#customers', 'ep', 'logic', 'mommy', 'swing', 'documentary', 'bang', '#reality', '#shooting', 'hook', '#enjoylife', '#loveher', 'rifle', '#colors', '#stop', '#event', 'tech', 'pitch', 'average', 'alex', '#rest', 'yup', '#podcast', 'mrs', '#growth', '#games', 'user', 'spirit', 'soft', 'european', 'possibly', 'replace', 'advance', 'ache', 'explore', 'sum', '#sale', '#luv', 'opposition', 'ref', 'al', '#stoked', '#ignorance', 'scary', '#words', 'topic', '#massage', '#charity', 'hateful', '#corruption', 'justice', '#isis', 'elect', 'ceremony', '#congratulations', 'nightmare', 'canadian', 'sour', '#newyear', 'recognition', 'hip', '#death', 'dancing', '#bike', '#sukhbir', 'protection', 'hood', '#waiting', 'pen', '#motivate', 'boston', '#stupid', 'select', 'danger', '#jocox', '#musicvideo', 'diy', '#prayfoheworld', 'phase', 'kkk', 'accord', 'jimmy', 'engineer', 'preview', '#gin', 'reading', 'grave', 'wit', 'guidance', 'pressure', '#ladies', 'bath', 'remix', 'nephew', 'shitty', 'therapy', 'confirmation', 'coupon', 'repoe', 'semi', '#datenight', 'surround', 'oppressive', 'internalize', 'trap', 'rough', '#jokes', 'desperate', '#makes', 'giphy', '#congress', 'faster', 'mateen', '#dogsarejoy', 'sexist', 'vid', '#romantic', 'ego', 'reflect', 'dollar', '#abrahamhicks', '#bubbles', '#simple', '#fitnessaddict', 'christ', '31', 'camper', 'ale', '#tan', '#working', 'entry', 'worldwide', '#actress', 'thankyou', 'highly', '93', '#sydney', 'fade', '#problem', 'handsome', '#as', 'grape', 'media', 'gel', 'twin', '#original', 'greet', '#goodluck', 'cheese', '#loss', 'sept', '#theconjuring2', '#violence', 'farm', 'productive', '#raghuramrajan', 'oakland', '#ramadhan', '#traitor', '#hopeful', 'conversation', 'obvious', '#smiley', 'plymouth', 'overcome', 'dey', '64', 'kindness', 'breathe', 'define', 'intelligence', 'crush', 'soed', '#worldoceansday', 'ideal', '#student', '#goodread', 'canada', 'neighborhood', 'popular', '#remember', '#pulsenightclub', 'pose', 'bond', '#pig', 'ag', 'secure', 'daddys', 'concept', 'ashamed', 'paicipate', 'goodness', 'delight', 'accident', '#fuck', '#winning', 'oitnb', 'nra', 'threaten', 'river', 'bash', '#flagday', '#bbc', '#tea', 'nut', 'surely', 'relaxing', '42', '#police', 'zero', '#enteainment', '#filter', 'wee', 'split', 'rss', '#shopalyssas', 'upgrade', 'anthem', 'conjure', '#funday', 'pc', '#instasize', 'bullshit', 'bestfriend', '08', 'treatment', '#remain', '#yyc', '#polishgirl', '#candles', '#toddler', '#runner', 'hus', 'woot', 'depressed', 'convince', '#job', 'tank', 'ios', 'oscar', 'oven', 'habit', 'ship', '#ny', 'deeply', 'french', 'capture', '53', 'item', '#t', 'outrage', 'rude', '#female', 'unbelievable', 'peek', 'strike', 'acceptable', '#f', 'logo', '#newlook', 'transform', 'goodnight', '#crafts', 'crisis', 'underway', 'bake', '#watch', 'fry', 'shocking', 'strawberry', 'seven', 'massage', 'mi', 'huh', 'ear', 'grant', '#etsy', '#lgbtq', 'destination', 'ibiza', 'premium', 'feedback', 'leeds', 'cafe', 'fbi', 'circle', 'grass', 'danske', '#starwars', 'selfish', 'men', '#trumps', 'industrial', '#throwbackthursday', '#learn', '#street', 'wakeuppeopl3', 'wash', 'championship', 'eyed', 'weigh', 'victory', '#done', 'photography', 'bell', 'appointment', 'tap', '#wattpad', 'chain', 'jam', 'reunion', '#bts', '#4', 'imagination', 'attractive', 'bin', '#more', 'resign', '79', 'heritage', '#priceless', 'condition', '#realtalk', 'probe', 'buzz', 'thinking', '#sketch', 'mam', '#princess', '#disneygatorattack', 'don', '#pokemon', 'wells', '#country', 'peak', 'january', '#cover', '#tonyawards', 'chinese', '#manchester', 'writer', 'upside', '#purpose', 'compare', 'bone', 'sample', 'equality', 'mast', '#grumpy', 'pub', 'determine', 'october', 'effective', '#euref', '#think', 'require', '#culture', '#quiet', '#dancer', 'egg', 'tgif', '#enough', 'fuckin', 'superb', 'immigration', 'jew', '#islamophobia', 'fargo', 'harm', 'lab', 'approve', 'duty', 'cloud', 'flash', '#superhero', '#one', '#salad', 'active', 'personally', 'appletstag', 'sadden', '#fl', '#shameful', '#bestsellers', 'spa', '#traveling', '#fish', 'boo', 'staer', '#nomnom', 'writing', 'rant', '#letsdothis', '#bluesky', '#singapore', '#hours', '#nzd', '#funtimes', '#neverforget', '#hawaii', 'rehearsal', 'kim', 'defame', '#mcdonalds', '#indie', '#angels', 'scott', 'syfy', '#orlandounited', 'chris', '#never', '#grandpa', 'basically', '#manga', '#starek', '#soccer', '#fact', 'sooo', '#fairytail', '#orange', '#coybig', '#heaven', 'net', 'premier', 'amazon', 'quantity', 'rg', '#sisters', '#rap', 'shadow', '#increasing', 'strange', 'mike', '#lovemyjob', 'meditation', 'bum', '#iloveyou', 'dawn', '#multiple', 'amodu', 'oprah', 'fantasy', 'slice', 'camera', 'bread', '#fashionblogger', 'premiere', 'sweat', 'rhetoric', 'sentence', '#desperate', '#xboxe3', 'sexism', '#lemans24', 'switch', '#stopracism', '#plan', '#congrats', 'prep', 'knee', 'rebeccas', 'background', '#guncontrol', 'amateur', '#choice', 'uncle', '#instafood', 'nationalist', 'unreal', '#nails', '#spirit', 'bleed', '#oil', 'un', '#fo', '#continuous', 'cooking', 'sculpt', 'theater', 'lion', '#dogsoftwitter', '#transformation', 'playa', 'dry', '#bae', 'vintage', '#istanbul', '#clean', '#n', '#always', '#goodbye', '#plants', 'honey', '#healthandfitness', 'wembley', '#sneezy', 'negativity', 'rome', 'cookie', '#recipe', 'disappear', 'sydney', 'donate', 'colleague', 'safety', 'nick', 'dump', '#1', '#thoughts', 'enteainment', 'package', '#whitepeople', 'pound', 'sway', 'scotland', 'heabreake', '#draw', 'utterly', 'century', '#africa', 'smiley', 'quiz', 'guilty', 'accuse', 'flow', '#roses', 'sweetie', '#mother', '#blessings', 'russian', 'showcase', 'depressing', '#parents', 'pit', 'corrupt', 'sink', '#listen', 'thailand', 'smash', 'fund', '#potd', 'thug', '#surprise', 'orientation', '#mensfashion', 'camping', 'solution', '#storm', 'caption', '#parente', 'lean', '#orlandoshoote', '#shine', 'fa', '#dreamcatcher', '#late', '#flight', 'yrs', '#dissapointed', 'differently', 'bury', 'censor', 'fruit', '#bashful', '#wishes', '#ride', 'brighten', '#latina', '#amazon', 'peaceful', 'pleased', 'corner', 'uni', '#mustread', '#povey', '#app', '#livelife', 'summeime', 'introduction', 'senior', '#tumblr', 'ahhh', 'gallery', 'sofa', '#launch', 'apology', 'dip', '#gunviolence', 'cnn', 'corruption', 'hrc', 'rapist', 'pocket', 'develop', '#auspol', '#orlandohorror', '#brunch', 'vinyls', '#imwithher', '#realestate', '#mc', 'photoshoot', '#beyou', 'thrill', 'birmingham', '#haha', '#glastofest', 'fella', 'repostapp', 'americas', '#pets', 'miserable', '#preorder', 'christians', 'occur', 'trial', '#wrong', '#relationships', '#nazi', 'bt', 'diversity', 'potus', '#irl', 'damage', 'champion', '#photoshoot', '#treat', 'lineup', '#g', '#sunrise', '#skincare', 'awhile', 'trick', '#fraud', '#gardening', 'shairi', 'obsess', 'preparation', 'duck', 'tower', '#wish', 'spoil', 'deny', 'hack', '#hr', '#tuesdaymotivation', '#deep', '#nothappy', 'vanilla', 'nite', 'principle', 'attract', '2014', '#fire', '#scifi', '#michelleobama', 'slap', 'surprising', 'extremist', '#switzerland', 'android', 'refer', '#selfietime', '#trust', '#happier', 'irish', 'cc', '#pregnancy', 'addition', '#pc', 'personalised', '#please', '#vscogood', 'killing', 'leadership', 'anna', 'pr', 'funding', 'mature', '#germanyhetalia', 'seed', 'motivation', '46', '#dublin', '#lyrics', 'region', 'impossible', 'progressive', 'gr8', 'cheeky', '#saturdaymorning', 'patience', 'grin', '#faces', '#catsoftwitter', '#disneyland', '#disgusting', 'cheesy', 'sauce', '#dc', 'photographer', 'johnny', 'justin', 'wage', 'grey', '#prayer', 'goody', 'prince', 'ahhhh', 'factor', '#bollywood', 'cutie', '#tomorrow', '#mindful', '#inequality', 'promotion', '36', 'lincoln', '#overwhelmed', '#payintheusa', 'shape', 'jewish', 'amsterdam', 'amendment', 'edinburgh', 'wo', '#onelove', '#blueeyes', '#bus', 'owl', 'mixed', 'upbeat', 'saturdays', 'jerry', '#newproject', 'tradition', '#olathe', 'suppoing', '#hat', '#batman', '#ladyboy', 'racing', '#makeuptransformation', 'fucked', 'moron', '#after', 'whisper', 'kscrashcorrectors', 'mouse', '#paradise', 'multiple', '#snow', 'ace', '#truestory', '#humanity', '#craft', 'shave', 'greeting', 'punish', '#kitchen', 'deceive', 'pregnant', 'regrann', '#vlog', 'unleash', '#national', 'clock', 'teenager', 'beep', 'tackle', 'seal', 'queens', 'tall', 'semitic', '#euro', 'wet', 'blm', '#ending', 'connection', '#producer', 'vet', 'wound', 'central', 'rep', 'miami', '#accessories', '#hour', 'grandma', '#restinpeace', '#missyou', 'script', 'freak', 'cruise', 'survey', '#momlife', '#antisemitism', 'woo', 'lyon', 'regular', 'greatness', 'perfection', '#039', 'vehicle', '#fat', 'santa', 'pin', 'rbc', 'pup', 'tournament', 'monthly', '#daddysgirl', 'oppose', '#hottweets', 'extend', 'convention', '#augusta', 'suddenly', 'garage', 'infinite', '#ex', '#idiot', 'combat', 'junior', '#fantastic', '#beachbody', 'courage', 'gamer', 'nonsense', '#hotel', 'snack', 'forgiveness', '#followback', 'mercy', 'file', 'andrew', '#ibiza2016', 'vegan', '#warcraftmovie', 'bias', 'living', 'gov', 'bjp', 'painting', 'cancer', '#depressing', '#pulseshooting', 'pant', '#fans', 'mindsconsole', '26th', 'skip', 'slide', '#royal', 'tan', 'thomas', 'shocked', 'lang', '#movies', 'tribute', 'dive', 'burger', 'contain', 'thi', 'sock', 'dem', '#papa', '#dont', 'harry', 'banana', 'motherfucker', 'overweight', '#arkansas', '#but', 'clip', 'founate', 'criticism', 'nigger', 'tight', 'sooooo', '#magical', '#windows10', '#webcammodel', 'monster', 'liverpool', 'fate', '#tattoosleeves', 'stoke', 'divide', 'ole', 'nohern', '#videogames', '#reinventimpossible', '#gayboy', '#homophobia', 'genuinely', '#mobile', '#gangs', '#greatday', '#lipstick', '#vehicle', 'resolve', '#pictures', '#attack', 'evidence', '#pissed', 'donation', '#sunglasses', 'journalist', 'whore', 'heel', 'useless', '#invited2jive', 'idol', 'slaughter', '#yesterday', 'appeal', 'emergency', 'bonus', 'individual', 'fred', 'empower', 'miscegenation', '8th', '#stafresh', '#seeklearning', '#hamilton', 'journalism', '#hippie', '#sucks', '#sweden', 'zelda', '#selca', '#hairdresser', '#shopthemint', 'jivemap', '#relaxation', 'jack', 'district', '#clothing', '#suppo', 'rd', 'paradise', 'failure', 'shis', 'lad', '#club', 'amen', 'leather', 'ipad', 'strip', 'beta', '#last', 'gossip', 'prison', 'everytime', '#parenting', 'billy', 'plate', 'rob', 'headline', 'grind', '#character', '#saturdaynight', 'flop', '#client', '#spirituality', '#actorslife', '#special', 'placement', 'wwe', '#shoutout', 'conspiracy', 'ordinary', 'bearer', 'nd', 'pal', '#season', '#back', '#bali', '#stupidity', '#shoppe', '#im', 'madness', 'edc', '#experience', '#progress', 'sushi', 'apament', '#compassion', 'max', '#engrus', 'mission', 'temple', 'coverage', 'freaking', '#likes', 'coolestlifehack', 'section', 'producer', '#ass', 'coast', 'rig', 'cmon', 'display', 'laughing', '#rainyday', 'personalise', '#xboxone', '#myself', 'med', 'glorious', '#service', '#bringiton', 'bot', '#comics', 'taco', '#gopro', '#christians', '#blogging', '20th', '#read', '#ink', 'soooo', '#is', 'flame', 'fraud', '#amsterdam', '#sho', 'bracelet', '#wwdc', '#seaside', '#besties', 'advantage', 'flourish', 'squad', '#giveaway', 'yell', 'fri', '#space', 'ms', 'cd', '#christmas', '#year', 'natalie', 'snatch', 'cos', '#gutted', 'modified', 'got', '#stressfree', '#mybihday', '#udtapunjableaked', 'legacy', '#hurryup', 'delighted', '#pharrellwilliams', 'civil', 'boost', 'gosh', 'emma', '#everyone', 'belgium', '#qotd', 'pharrell', '#chat', '#humanrights', 'trigger', 'repost', 'danny', '#whiteprivilege', '#beachlife', '#dumb', '#sanfrancisco', 'lipstick', '#aloha', 'ability', '#bright', 'majesty', 'fest', 'annoying', 'gate', 'archive', '#upsideofflorida', 'decline', '13th', 'mount', '#newswithed', 'bihdays', 'supply', 'classy', 'drawing', '#butterfly', 'panel', '#boat', '#gaypride', 'cure', '30pm', '#weed', '#marvel', '#worldwide', 'inner', 'you', '#grunge', '#gifts', 'restore', '#tenerife', 'genius', 'debut', 'shuaibu', 'deadly', '#hugs', 'tube', 'conduct', 'saint', '#coldplay', '#laughing', 'mod', 'nap', 'guitar', 'owe', 'thread', 'celebrity', '#giftideas', 'toe', '#baseball', '#greatful', 'lift', 'omar', '#management', 'lisa', '#fingerscrossed', 'disneyland', 'ba', 'comprehend', 'eac', '#wealth', 'happ', '#evil', 'wind', 'horror', '#disgraceful', 'warren', '#only', '#mountains', '#ghostbusters', 'branch', '#lokiday', '#relatable', 'libey', '#indonesia', '#religion', '#punjabis', 'destiny', '#freespirit', '#pencil', '#goodtime', 'subject', 'oops', 'maintain', 'belief', '#horrible', 'rent', 'km', 'prom', 'louis', '#jacksonville', 'reduce', '#videos', 'constantly', '#adidas', '#grow', 'brooklyn', '#ad', '#mydubai', 'maui', '#donthecon', 'grill', '#confidence', 'fixture', 'cloudy', '#fabulous', '#beats', 'thursdays', 'crooked', 'spew', 'mug', 'sand', 'diego', '#suit', 'hilarious', 'brochure', '#tips', 'scotiabank', '#girltime', 'alternatively', 'taylor', 'terrific', 'feelin', 'eek', 'scare', 'melt', 'bathroom', '#stream', 'ridiculously', 'parking', '#staytuned', '#wales', '#adult', 'disappointment', '#lady', 'slim', 'prefer', 'outta', 'almighty', 'browning', '#cafe', '#marketing', '#advice', '#walking', 'walker', '#army', '#old', 'resist', '#hero', '#environmental', 'heavy', '#newjob', 'patio', 'spectacle', 'hamilton', 'homeopathic', 'familys', 'refund', 'depth', 'anxious', 'washington', 'propaganda', '#husband', 'slam', 'exhibition', '#break', '#jewellery', '#moving', 'bowling', 'cooper', '#shoote', '#war', 'fee', 'greece', '#gig', 'empathy', '#island', 'ben', 'proper', 'forest', 'patient', 'senator', '101', 'ditch', '#competition', 'tire', 'earlier', 'patch', '#markete', 'conditioning', '#wal', '#cancer', 'inspiring', 'settle', '#rape', 'maker', 'chief', '#lake', '#republicans', '#focused', '#topless', 'darkness', '#this', 'sup', 'ryan', '#open', '#bbw', '#lush', 'volunteer', 'dan', 'greed', 'gordie', 'outdoor', 'china', '#memory', '#human', 'be', '#muhammadali', '#muslims', 'newcastle', 'justify', 'collect', 'republicans', '#trump2016', '#abundance', 'preach', 'technology', '#sales', 'ideology', 'refugee', 'sharpen', 'swiftly', 'stray', '#fallschurch', '#royalascot', 'originally', 'tent', 'minded', 'rational', 'employment', 'jeff', 'sam', 'recently', '#momtips', 'encounter', 'furniture', 'activist', '#wishe', 'insight', '#cooking', 'rush', 'casino', 'lane', '#discrimination', 'programme', 'expression', 'hangout', '#hairstyle', 'dublin', 'plain', 'choke', '#badal', '#high', 'ffs', 'feminism', '#archangels', 'soccer', 'magical', '#cycle', '44', '#what', 'recommend', '43', 'anf', 'economy', 'cope', 'actress', 'anz', 'glamorous', '90th', '#sandiego', '#babe', '#homesweethome', '#jesus', '#secret', '#99c', 'necklace', 'cherry', 'brisk', 'weekly', 'nah', 'museum', '#american', '#afternoon', '#feminist', '#glutenfree', 'oppounitie', '#d', '#phillysuppophilly', '#exploring', 'captain', 'indigenous', '#worry', 'iq', 'jackson', '#metal', '#warriors', 'drown', 'desk', '#melbourne', 'cocktail', '#proverb', 'rick', 'sorrow', 'quotestags', 'tax', '#quotestags', 'infographic', 'bunny', 'fang', '#vividsydney', 'slave', '#jeffsessions', '#strawberries', 'adorable', 'billion', 'unknown', 'rap', '#lightroom', '#brain', 'terribly', '18th', 'slander', 'hunger', 'neighbour', '#tweet', '#optimistic', '#myhappycapture', 'gentle', 'ghazal', 'optimistic', '#slimmingworld', 'outrageous', 'woe', 'era', '#paladino', '#goodbook', 'packing', '25th', 'dedicate', 'cpi', '#girly', '#android', '#smilepowerday', '#stage', '#newstar', '#nazis', 'lame', '#quality', '#airpo', '#bear', '#study', 'wallet', '2005', '#interiordesign', 'poet', 'pearl', 'homemade', '#queenat90', '#beutiful', '#destiny', '#exhausted', 'expand', 'clown', '#resistance', '#thevoice', 'abandon', 'march', 'status', 'brunch', '#movingon', 'meat', 'notification', '#cocktails', 'tyler', '#livemusic', '#college', 'baseball', 'rider', '#m', 'liye', '#turnup', '#smoke', 'tend', '#leeds', 'hav', 'fancy', '#yogi', '#sand', 'dev', '#delighted', 'tht', '#tranny', 'dallas', 'marijuana', 'bust', '#cardiff', 'pastor', 'gas', '#mac', 'comedy', 'zealand', '#kharkivgram', '#fedup', 'ultimate', '32', 'vile', 'pundit', '#7', 'modern', 'steph', 'kisses', 'medical', 'mater', 'atmosphere', '#favorite', 'commitment', '#hi', 'playing', 'crown', 'spray', '#jealous', 'po', 'modify', 'extremism', '#liverpool', '#desse', 'mumbai', 'blanket', 'attraction', 'disorder', 'yesterdays', 'flood', 'advanced', 'edition', '#greens', '4o4o4', 'disrespect', 'lounge', '#cutie', 'nt', '#rant', 'nope', '#brokenhea', '#eu', 'unchanged', '#ohio', '#worried', 'dubai', '#attitude', 'mentor', '#hippy', '#dystopian', 'accent', 'hindu', 'german', 'exo', 'juice', '#customerservice', '#fool', 'craft', '#djlife', 'sheet', '#kh', '#kharkiv', '#overwatch', 'acc', '#determination', 'mon', 'investment', 'personality', '#tattoos', '#ashamed', 'management', 'dictionary', '52', '#appreciate', 'loving', 'passenger', 'unfounate', '#unforgettable', '#career', 'numb', '#lifehacks', 'bow', 'salon', 'sandwich', 'vocal', '#ojmadeinamerica', 'z', '#jump', 'inflation', 'dave', '#cutest', 'delhi', 'indians', 'brussels', 'silver', '#frustrate', '#honored', '#mtb', 'broadcast', '#shit', '#fridays', 'potter', 'aid', 'conclusion', 'transition', 'blatant', 'spoiler', 'regardless', 'mega', '#lies', '600', '30am', 'vinyl', 'dismantle', '#take', '38', 'exit', 'profit', 'punishment', '#results', 'se', 'navy', '#final', 'slip', '#sarcasm', '#u', 'hepburn', '#mommy', 'li', 'solid', 'separate', 'custom', 'jus', '#ugly', 'whisky', '#colourful', '#drinking', '#nomakeup', 'testing', 'ninja', 'ion', 'wenger', 'acknowledge', 'bend', 'healing', 'ye', 'clap', 'directly', 'salute', '#talk', 'myth', 'western', '#policebrutality', 'ps4', 'wil', 'emoji', '#pamper', 'nazi', 'edge', '#someone', 'satisfy', 'forgot', '#capitalstb', 'happier', 'hunt', '#angry', 'putin', '#lion', '#buzzing', 've', 'negro', 'priority', 'obsessed', 'commute', 'punch', '#wellbeing', 'oppa', '#cheer', '#gameshow', 'hoshi', 'cameron', '#chihuahua', '#nephew', '#angel', 'kanye', 'persuade', '#clothes', 'mk', '#newday', '#present', '#arianagrandedrawing', 'victoria', '#bearlovestravel', 'toronto', '#prayforchristina', 'liam', '#cow', 'gary', '#riclswtravelbook', '#glastonbury', 'ga', 'broad', 'bloom', '#disgusted', '#elegant', 'cage', '24th', 'hawaii', 'keynote', '#ford', '#immigrants', '#expat', 'approach', '#instaaoftheday', '#singing', '#alabama', 'wade', '#shocking', '#hillaryclinton', 'phd', 'private', 'livelypics', '#spotify', '#nashville', '#raining', 'stomach', '#wild', 'creation', 'alright', 'stanley', 'romantic', 'guarantee', 'halfway', '#exciting', '#thrive', '#smileyface', 'smith', 'latepost', 'sana', 'pie', '#girlpower', '#hashtag', 'organic', 'overall', 'swift', '#triste', 'encouragement', '#putinspuppet', 'platform', '#designer', '#alive', '#fra', '#miss', 'tooth', 'tokyo', '#liberals', 'depament', 'sparkle', '#hatecrime', 'crave', '#whitegenocide', '15pm', '#bitch', 'injustice', 'philip', '#boring', '#tire', 'scout', '#tomhiddleston', 'hopeful', '#soon', 'heck', 'caoon', 'glasgow', '#newyearseve', '#ebook', 'modi', '#youth', '#engaged', '#cousin', '#ios10', '#coach', 'kelly', 'omit', 'str', '#selfporait', 'greek', 'kro', '#conference', 'profession', 'yu', '#fifa17', 'helpful', 'opposite', '#na', 'kg', '#cologne', '#obamas', 'tha', '#trainhard', '#smaphone', 'fouh', '#nuascannan', 'noise', '#southbeach', '#person', '#just', '#slavery', '#easy', 'pad', '#fotokuapp', 'mud', 'steam', '#pixar', 'bucket', '#teamwork', '#harassment', 'curse', '#atlanta', '#winterfashion', 'payday', '#invest', '#families', 'grandmother', 'settlement', '#samsunggalaxys2', '#post', '#creativity', 'tease', '#classroom', 'dozen', 'darling', '#fridayfun', '#finished', 'unable', '75', 'produce', 'poman', 'bk', 'stereotype', 'contestant', 'corporate', 'shameful', 'backyard', '#marathon', 'sentiment', 'chef', 'criticize', 'sob', '#info', '#uae', '#chronicpain', 'momma', '#h', 'kitten', 'booking', 'rare', 'ash', '#guncontrolnow', 'compete', 'workplace', 'battlefield', '#purple', 'passionate', 'prevail', 'feat', 'reward', '#instafashion', 'institution', 'sunglass', '#her', 'ink', '#everyday', 'ridiculous', '#lovehim', 'drain', '#vote', '#doodle', 'historic', 'succeed', '#christianity', 'rub', 'submit', 'del', '#caoon', 'ending', '#cruel', 'melbourne', 'erase', 'creativity', 'ooh', 'phelps', 'naturally', '#ios', '#asianladyboy', 'endorsement', 'macbook', 'pple', 'comedian', 'palestinian', 'donkey', '#lovemyfamily', '#him', '#catlover', 'madrid', 'collage', 'finn', 'threat', 'perfectly', '#fashionillustration', 'honour', '#wooden', 'dummy', '#feelthebern', '#lessismore', '#poor', 'mars', 'gutte', '#focus', '#asia', 'blicqer', 'broken', 'shed', 'ku', 'working', 'application', '#ramadankareem', 'harmony', '#montreal', 'mourn', '#prayingfororlando', '#tupac', 'um', 'lb', '#glad', 'pilot', 'rescue', 'q', '#give', '#nationalbestfriendday', 'semester', 'monthsary', 'teammate', '#skate', '#marijuana', '#glitter', '#grind', 'ceainly', '#doggy', '#comeonengland', 'password', 'unity', 'constitutional', 'jon', 'shane', '1q', '#irish', 'birthday', 'cereal', 'palette', 'hurry', 'brutality', 'heas', '#adultery', '#bullying', 'closet', 'doom', 'goat', 'eyebrow', 'noon', '#crochet', 'basket', 'sticker', 'badge', 'disturb', 'thumb', '#dementeddonny', 'cherish', 'foreign', 'charles', '#kindle', 'legendary', 'financial', '#5', '#dory', 'cycle', 'collapse', 'surgery', '#students', '#ascot', 'asset', 'patiently', 'nowlinkup', '#bingewatching', 'sensitive', 'tee', 'prime', 'server', 'lumpy', '#disappointe', 'pursue', 'tim', '#exams', 'economic', 'doc', 'scientist', 'lap', '#strawberry', 'virginia', '#train', 'nurse', '#haiku', 'hd', '#instaboy', '700', '10k', '#maccosmetics', '#pinoy', 'lost', '#power', 'classroom', 'fe', 'acceptance', '#redhead', '#whitesupremacy', 'learning', '#ebay', 'integral', 'bonding', 'medal', 'have', 'elizabeth', 'bbh', '#idol', 'bruh', 'wipe', '#woohoo', '#democrats', '#saterday', 'scroll', '#minions', '#euros', '#igersbnw', '#instafun', 'memorial', 'data', '#thebest', 'brithday', 'tummy', '#blesse', '#houston', '2012', 'ie', '#fridaynight', '#newyorkcity', 'broadway', 'australia', 'creepy', 'scratch', '#three', '#instalove', '#productive', '#songwriter', '#bye', 'opera', '#johnnydepp', 'viral', '#healthyliving', '#cali', '#poems', '#jocoxmp', '#voiceover', '#steak', 'universe', '#challenges', '#funeral', 'aunt', '#treason', '#sorrynotsorry', 'woop', '#english', '#y', '#pharrell', 'breast', 'retro', 'mac', '#gamergirl', 'champ', 'bn', '#awork', 'henry', 'audience', 'bacon', 'katie', 'mccain', '#camgirl', 'feminist', 'ski', '#worke', 'asleep', '#p2', '#cdnpoli', 'spit', '17th', 'aug', '#newcastle', 'circumstance', 'lucy', 'bron', '#butterflies', '#canadiangp', '#call', 'gen', 'disaster', 'starbucks', 'marathon', 'arabic', '#dubai', 'goodmorne', '#changes', '#succes', '#staypositive', 'maryland', '#dope', 'relative', 'hehe', '#rugby', 'irony', '#from', 'square', 'denounce', 'allege', 'smdh', 'cape', '#message', 'gentleman', 'cracker', '#instafollow', '#korea', 'carpet', '01', 'bihdaysway', 'homework', 'rave', 'laziness', 'mary', 'eh', 'brazil', 'legal', '#lit', 'impoance', '#cosplay', 'trophy', '#boom', 'agency', '#l', 'curb', '#familyfun', 'witch', '#bridesmaids', 'prob', '#14', 'deck', 'tommorow', '#infographic', 'neutral', 'outlet', 'italian', 'ape', '#cook', 'forum', '#fly', 'feliz', 'betray', 'argentina', '#much', '#justsaying', 'jacksons', 'trek', 'ecstatic', 'beware', 'monetary', 'utter', '#got', '#haircut', '#zelda', 'berlin', '#was', '#otaku', '#terrible', 'sickening', 'surface', '#rapist', '#anti', 'boys', 'openly', '#fave', 'anime', '#smallthings', 'soak', '74', '#grandma', 'subtle', 'spirited', 'candy', '#growthhacking', '#instagramers', 'wig', 'voltaire', '#gel', '#for', 'veggie', 'bible', 'twist', 'unfollowe', 'familiar', 'unfit', '#bristol', 'ss', 'days', 'icon', 'isolate', 'daisy', '#hbd', 'asia', 'asians', '#awareness', '#pampered', 'puppet', 'mere', 'usb', '#wimbledon', 'norm', '#winner', 'narrative', 'auction', '#end', 'internship', '#question', 'tweeter', 'abc', 'storage', 'rating', '#pueorico', '#internet', '#again', 'brainwash', '#insure', '#selfharm', 'heaache', '#shooter', '#promise', '800', '#praying', 'disappointing', '#ignorant', 'authority', '#genocide', 'tmrw', 'masse', 'chelsea', '73', 'council', 'colombia', 'bentley', 'scam', '#ancient', '#myhappyplace', '#jeeplife', 'raid', 'hormone', 'calico', 'camden', '#wakow', 'shopper', '#since', 'fasting', '#blowing', 'hometown', 'labour', 'to', '#horse', 'qualified', 'hudson', 'brick', 'proudly', 'avengers', 'symptom', 'going', 'jar', '#pos', 'bangkok', 'attorney', '#rains', '#nz', 'slut', 'gratitude', 'adve', '#lifeisbeautiful', '#workhard', '#breakup', 'luis', '#alhamdulillah', '#viral', '#9', 'yum', 'hai', 'taeil', '#gokaldas', 'trim', 'plot', 'foolish', '#carwash', 'jay', '#hacking', 'veteran', 'discount', 'texte', 'affair', '#royaltyfreemusic', 'checkout', '#background', '#fav', 'motto', '#hijab', 'cunt', 'identify', 'wealthy', 'ana', 'monroe', '#afghanistan', '#loveconquershate', 'palm', '#ableism', 'aw', 'cardiff', '#menswear', 'kern', '#shofilm', 'buyer', '#bihdays', 'careful', 'agr', 'brighton', '#browser', '#harrypotter', 'sexuality', 'vincent', '#vietnam', 'quack', 'politically', 'grove', 'charming', 'goofy', 'making', '#prison', '#toast', 'refresh', '#flowerlove', '#gm', 'luke', 'jp', '#travelling', 'dish', 'paicularly', '#amo', '#lollipop', 'awork', 'mfs', '#abuse', 'loyal', 'height', 'inauguration', '#writerslife', 'reggae', '#prosecco', 'curious', '#paper', '#redlips', '#amwrite', 'childish', 'anyways', '51', '#hilarious', '#down', '#dumptrump', '#denim', 'stair', '#lfc', 'smoothie', 'contagious', 'mm', 'element', 'gunman', '#nhs', '#useless', 'kylie', '#em', '#mine', '#novel', '#office', 'charlotte', '#drive', 'grip', 'suggest', 'beard', '#havefun', '#amazed', 'airline', '#decor', 'britain', '#lightning', 'nottingham', '#dese', '#sexualpredator', '#trumpuniversity', 'fascist', '#cactus', '#mondaymorning', 'mayor', 'disgusted', 'assess', '#ego', '#springfield', 'whack', '#technology', '#facts', 'employ', '#hospital', '#moon', '#paner', 'te', '#unpresidented', 'crude', 'simon', 'inn', '#follower', 'prostitute', '#latergram', 'giggle', 'monitor', 'genetic', '#punjabi', 'selena', 'meaning', '#godbless', '#japanese', '#sustainable', 'delightful', '#doglover', '#pissedoff', 'birds', '#excited', '#zoo', 'tiger', 'boycott', 'depend', 'pearly', 'accountable', '#italian', 'immediately', '#society', 'ar', 'percent', 'sore', '#warcraft', '#rohingya', 'misogynist', 'keith', '#bffs', 'baba', 'jr', '72', 'minister', '#prom', '#basketball', 'mill', '#conjuring2', 'renew', 'balloon', 'lobster', 'comic_strip', '#hrc', '#healthyeating', 'pb', 'paycheck', 'malaysia', '#delhi', 'mighty', '#dogslife', '#river', 'dee', 'draymond', '#luckygirl', 'setup', 'hijack', 'intolerance', 'superhero', 'publish', 'gunna', '#bunny', '10th', 'dec', '#musician', 'maria', 'oooh', 'minneapolis', 'fighter', 'whip', '#modelling', 'brian', 'decent', 'transfer', 'globe', 'pot', 'wilson', 'aus', 'happend', 'assure', '1998', '#indiegame', '400', '#reason', '#tip', '#stopthehate', 'concerned', 'toxic', 'petty', 'breeze', '#brave', '#employees', 'ibooks', 'meaningless', 'guru', '#heabreak', 'temporary', 'dearly', '#allsmiles', 'protester', '#thankfulthursday', 'weakness', '#oitnbseason4', 'confession', 'mummy', '#uniteblue', '#democraticpay', 'visa', 'bedroom', '#lazy', 'gee', '#karaoke', '#landscape', 'mps', 'prof', '#hatespeech', '#sma', 'pole', '#tree', 'spike', 'unfair', '#farming', '#brand', '#mitb', 'arrival', '#dnaquotes', '#ripantonyelchin', '#dna', '#relationshipgoal', '#mama', '#singlelife', 'cum', 'viewer', 'tule', 'mornin', 'stem', 'jewelry', '#see', 'sunrise', '#teacher', '5k', 'gud', 'resignation', '#colour', '#trumpsamerica', 'anchor', 'redneck', 'appalling', 'overpower', 'venture', '#orlandostrong', '#band', '#cousins', 'hint', 'gin', 'truthful', 'loneliness', '#fasting', '#shoplocal', 'resident', 'relaxed', 'lola', 'buck', '#psychology', 'dma', '#hateful', 'susan', 'lauren', '#40', '#salute', 'verify', 'impressive', 'johnson', 'dope', '#place', 'tolerate', '#lovewins', 'governor', 'vivacious', 'agent', 'intend', 'philippines', '#nda', '106', '#buy', '#bees', '#sunbathing', 'packed', '#feels', 'poems', '#brokenquotes', '#thegoodlife', 'properly', '#conflict', '#justinb', 'stab', '#divulgaoeparceria', '#pumped', '#edit', 'perspective', 'glow', '#star', 'mob', 'alongside', '#drama', '#haford', '#navy', 'ove', 'dese', '#playing', 'alumnus', 'versa', '#coaching', 'nuure', 'audition', 'trolling', '#download', 'ranger', 'baltimore', 'electric', 'esteem', 'laura', '#longweekend', '#reunited', 'acquire', '#philippines', 'nicola', 'leftist', '#clarity', 'org', 'juan', '#beachday', '#busy', 'emea', '#minecraft', 'assessment', '#collection', '#3', '#em2016', 'coward', '#wanderlust', '#inked', 'tactic', 'hulk', 'equate', '#puppylove', 'nov', 'exclusive', 'core', 'outcome', 'emotionally', '#come', 'sow', 'awww', '#stories', 'frustrated', 'stepdad', '#poster', '#colours', '#radio', '#panda', 'drum', '#vinyl', 'admin', 'pittsburgh', '#official', 'theory', 'smoking', 'webster', 'rice', 'developer', 'prospect', 'ascot', 'academy', '#koreans', 'triumph', '#curvy', 'dislike', '#day1', 'rugby', '#medical', 'committee', '#mallorca', '#dancers', 'unite', 'steak', 'wholesome', 'combo', '#thick', '#traveler', 'grandfather', 'hollywood', '#staystrong', 'earp', '#sing', 'impressed', 'udta', '#cloudchaser', 'unemployment', 'xo', 'performer', 'trading', '#moron', '#ger', 'ounce', 'mentally', '#double', '#leather', 'hoo', 'throwback', 'income', 'davis', 'israeli', 'niece', '#gypsy', '#crystals', 'compassion', 'romance', 'alot', '#beautifulday', 'outline', 'ray', 'skinny', '#decors', '#relationshipgoals', 'knw', 'glitter', '#movement', 'lure', '#flashbackfriday', '#determined', '#warm', 'similar', '#drakeandjosh', '#midweek', 'los', '#curlyhair', '#cleaneating', 'investigation', 'sh', 'evolution', '#oitnbchat', '#orlandolove', '#episode13', 'webcam', 'gp', 'iconic', 'unlimited', '#zionism', '#motorcycle', '#beautifulsmile', 'et', '#smilee', 'rom', 'beginner', '#mounts', '#yeah', '#prince', 'scan', 'hooligan', 'peter', 'stroll', 'straw', 'ton', 'gators', '#whisky', '#chile', '#classic', 'magazine', '34', 'jacket', '#getaway', '#tedtalks', 'marine', '#personaldevelopment', '#fitmom', '#pug', '#cedarrapids', '#website', '#shrm16', '#climatechange', 'decorative', 'popcorn', 'olive', 'treason', '#yeg', '#worship', '#wildlife', 'ps', 'running', '#jamaica', 'queue', 'mis', 'pour', '#ky', 'bean', '#rwnj', 'bowl', 'thalaivaa', '#cricket', '#truelove', '2013', '#spa', '15th', '#growup', 'hustle', 'distress', 'van', 'zen', 'thin', 'standing', 'depress', '#amreading', 'gross', '#citation', 'fascinating', 'frame', 'sip', '#exo', 'andreas', '#staups', '#weareorlando', '#loneliness', '#fringe', 'breed', 'cannon', '#petal', '#british', '#breathe', 'tlc', 'fare', 'talking', 'chaos', 'onion', '#cannabis', 'brew', '#rahulgandhi', 'wifi', '#internetmarketing', 'constitution', '#freemilo', 'graceful', 'volatile', 'legit', '#daily', '#indieauthor', '#vr', '#natsu', 'critical', '#gross', 'guys', '#afraid', 'daniel', '50th', '#makemoney', 'meme', '#fight', 'aside', '#paint', 'grader', '#unitedstates', 'spotlight', '#gamers', 'wi', '#happines', 'discrimination', 'playoff', '#transition', '#ghost', 'networking', 'snake', '#drums', 'psychological', '#latino', 'straighten', 'adopt', 'wide', '#badday', '39', 'motorcycle', 'voting', 'ko', 'estate', '#dl2016', '#staff', '#cookies', 'unpack', 'aware', '#opkillingbay', 'chant', 'flyer', 'lily', '#security', 'hmm', 'depaure', 'gettin', 'puff', 'ho', 'retire', '#top', 'behavior', 'legally', 'tumblr', '#bag', '#local', 'nicole', '#msm', 'steady', '#ig', 'climate', 'gaming', 'selection', '@us', '#teamshide', 'donor', '#everything', '#postive', 'favor', '#apaheid', '#shideism', '#k', 'devil', '#joyful', 'jihad', '#victim', 'monsoon', '#camp', '#activities', '#bitter', 'tone', '#eastcoast', '#e', 'invest', '#our', 'whoa', 'sketch', 'replay', 'prop', 'cruel', 'rebound', 'fold', 'victorious', 'crib', 'multi', '#spoilt', '#eatclean', 'enthusiasm', 'tennis', '#learning', '#achieve', '#sharing', '76', 'headache', 'quad', 'dustin', '#edc', '#cotd', 'castle', '#goldenretriever', '#care', 'ke', '#here', 'grandparent', 'murderer', '#healthylife', '#smilemore', 'nab', 'appearance', '#bigbang', 'motivate', '#necklace', 'spare', 'wreck', 'earring', '#playinggames', '#frog', 'suppoive', 'invade', 'external', 'ghost', 'advise', 'joint', '#trende', 'injury', '#myworld', 'megan', 'atlanta', 'heabreak', 'satisfied', '#fearless', 'cardinal', '#cars', '#likescam', 'frog', 'batman', '50%#islamic', 'landholding', '#ever', 'shatter', '10%#all', '#teach', '#diversity', '#ridiculous', 'friyay', 'allen', 'enchanting', '#insane', 'keshis', 'latin', '#pedophilia', '#incest', '#selfies', '#croatia', 'seasonal', '#action', 'spanish', 'mytraining', 'carnival', '#cuddles', 'cube', 'khan', '#re', 'coconut', 'gs', '#taiwan', 'venice', '#tanhai', '#11', 'semitism', '#community', 'anon', 'gray', '#deleteyouraccount', '#bridetobe', 'despise', '#value', '#revenge', '#adele', '#lovequotes', '99p', '#visiting', 'honesty', '#loveofmylife', 'swap', 'ukraine', '#wakeupamerica', '#silent', '#@user', 'westpac', 'firefly', 'midnight', 'stall', '#tennessee', 'broke', 'etsy', '#radicalisation', 'virgin', 'chaser', 'photograph', '#rad', 'ceo', '#mtv', 'mock', '#on', 'overload', 'holidays', 'compose', '#drake', 'delegate', 'preppe', '#fatherday', 'visitor', 'salut', '#lips', 'backwards', '#thinking', 'houston', 'commerzbank', 'nominate', 'wid', 'streaming', 'flcrashcorrectors', 'democratic', 'dread', 'brutal', '#hand']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5EvjChBdJsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95bc1f40-936f-47fe-87a6-b483a2c83725"
      },
      "source": [
        "# Print the word vector (100-dimensional) representation of a particular word.\n",
        "print(unsupervised_model['love'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.30345777 -0.02664436 -0.48690012 -0.12322477  0.20298533  0.6469242\n",
            " -0.12125882 -0.06383161  0.32793236  0.44392973  0.08475346  0.2642347\n",
            "  0.31127265  0.3674754  -0.5968394  -0.23701833  0.2754445   0.28434968\n",
            " -0.11251639 -0.30411988  0.07977807  0.04600069  0.42844358  0.01662834\n",
            "  0.31693837 -0.43812928  0.22705     0.11845665 -0.4396209   0.59830695\n",
            "  0.01588855  0.05112264 -0.8107919  -0.10927011 -0.40397915 -0.330086\n",
            " -0.4688317  -0.8980728  -0.0783285   0.34643972  0.20025347  0.6191598\n",
            "  0.5537351   0.40460432 -0.17218041  0.14738113 -0.13200775  0.20507558\n",
            " -0.37343642  0.16191173 -0.07221972 -0.07308648  0.09036505 -0.09267928\n",
            " -0.16544695  0.04552644  0.02728527  0.5201551   0.18873724 -0.00295098\n",
            " -0.01188896  0.42409924  0.6710028  -0.07485198 -0.01827253  0.05718816\n",
            " -0.37601697  0.06879427  0.15553632 -0.2989822  -0.6240012  -0.38962668\n",
            " -0.19891742 -0.06294543  0.2601991   0.00143086 -0.03951265 -0.12503795\n",
            "  0.5739185  -0.47947788 -0.14917994  0.12212523  0.24197477 -0.24451804\n",
            "  0.30359018 -0.15334527 -0.07100235  0.16227417 -0.16048336 -0.45639446\n",
            "  0.78198236 -0.27506772  0.64775974 -0.505597    0.0424615  -0.0466671\n",
            "  0.25055522  0.30536    -0.08353104  0.08734836]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNAgS37HdQwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64083e48-cd2a-4f20-be11-f8be638b4b2e"
      },
      "source": [
        "# Find the word vectors that are \"closest\" to a given word.\n",
        "print(list(unsupervised_model.get_nearest_neighbors('Trump')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0.980888307094574, 'trump'), (0.9533953070640564, 'obamas'), (0.9478312730789185, 'obama'), (0.9466777443885803, '#neverump'), (0.9454813599586487, 'paladino'), (0.9449848532676697, 'fascist'), (0.9396200776100159, 'republican'), (0.9323604702949524, 'republicans'), (0.9296003580093384, 'campaign'), (0.9294282793998718, '#dumptrump')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BaJ1OCpdc_W"
      },
      "source": [
        "# Explore using fastText in a Scikit-Learn pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2NVDakEfphY"
      },
      "source": [
        "# Read in a csv file that contains a string with every unqiue word found in the set of tweets.\n",
        "unique_df = pd.read_csv(\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/intermediate_output_files/unique_words.csv\")\n",
        "\n",
        "# Grab the long string of unqiue words from the dataframe.\n",
        "unique_words = unique_df.loc[unique_df.index == 0, 'Unique_Words'].to_numpy()[0]\n",
        "\n",
        "# Split the string at white spaces to get a list of unique words.\n",
        "unique_words = unique_words.split(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPONpyUrdjr5"
      },
      "source": [
        "# Since fastText generates 100-dimensional vectors for each word, we may not be able to use each words entire vector representation when training supervised models.\n",
        "# The goal is to come up with a single vector that represents the entire tweet. One option would be to represent the tweet vector as the mean of the word vectors\n",
        "# for all the words it contains. \n",
        "\n",
        "# The MeanEmbeddingVectorizer class below can be used in a scikit-learn pipeline. When applied to a set of tweet strings, this class will take tweets one at a time and\n",
        "# use a dictionary that maps each unique word to its learned fastText word vector representation to create word vectors for each word in the tweet. Then, all word vectors\n",
        "# for the tweet are averaged to create a single \"tweet vector\", which is then returned.\n",
        " \n",
        "# Note: This class was inspired by a book written by Joydeep Bhattacharjee. I made some custom modifications to the class, specifically expanding out the code to make it\n",
        "# easier to see what operations are being performed.\n",
        "\n",
        "# For more context, reference his book, which can be found here: https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781789130997\n",
        "\n",
        "class MeanEmbeddingVectorizer(object):\n",
        "\n",
        "    def __init__(self, ft_wv):\n",
        "        self.ft_wv = ft_wv\n",
        "        if len(ft_wv)>0:\n",
        "            self.dim = ft_wv[next(iter(unique_words))].shape[0] \n",
        "        else:\n",
        "            self.dim=0\n",
        "            \n",
        "    def fit(self, X, y):\n",
        "        return self \n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "      mean_of_word_vectors = []\n",
        "\n",
        "      # For each tweet in our training set (that we have converted to a list of clean word tokens).\n",
        "      for clean_tweet_token_list in X: \n",
        "        \n",
        "        # Create a list to hold the FastText word vectors for each word in the tweet.\n",
        "        this_tweet_word_vectors = []\n",
        "\n",
        "        # For every word in a particular tweet.\n",
        "        for word in clean_tweet_token_list:\n",
        "          \n",
        "          # Initialize the word vector for this word to be a 100-dimension vector of all zeros.\n",
        "          this_words_vector = np.zeros(self.dim)\n",
        "          \n",
        "          # If we have a valid word vector for this word, use the valid word vector instead of the zero vector.\n",
        "          if word in self.ft_wv: \n",
        "            this_words_vector = self.ft_wv[word]\n",
        "          \n",
        "          # Append this word vector to the list of word vectors that make up this tweet.\n",
        "          this_tweet_word_vectors.append(this_words_vector)\n",
        "\n",
        "        # Create a single 100 dimensional vector that is the (element wise) mean of all word vectors that make up this tweet.\n",
        "        mean_vector = np.mean(this_tweet_word_vectors, axis=0)\n",
        "\n",
        "        # Append this mean vector to the list of mean vectors (this list will have one mean vector for every tweet in our dataset).\n",
        "        mean_of_word_vectors.append(mean_vector)\n",
        "      \n",
        "      return np.array(mean_of_word_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovv9wxuWgAsm"
      },
      "source": [
        "# Load the model of word vector representations that was trained in the previous section.\n",
        "ft_model = load_model(word_vector_model_filepath)\n",
        "\n",
        "# Create a dictionary mapping each unique word to its fastText word vector.\n",
        "word_vector_dictionary = {word : ft_model.get_word_vector(word) for word in unique_words}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdfkUfNKg1H7"
      },
      "source": [
        "# Create the feature and target vectors.\n",
        "X = ft_df['Clean_Tweet'].to_numpy()\n",
        "y = ft_df['label'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwZJ9v6vgcq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32413e0c-a63e-4cca-9181-ab5ccb76f2b2"
      },
      "source": [
        "# Create a pipeline using our fastText mean embedding vectorizer and a stochastic gradient decent classifier.\n",
        "sgd_model_pipeline = Pipeline([(\"ft_word_vectorizer\", MeanEmbeddingVectorizer(word_vector_dictionary)),\n",
        "                               (\"SGD_Clf\", SGDClassifier())])\n",
        "\n",
        "# Use cross validation to calculate the f1_score of the pipeline above.\n",
        "sgd_clf_score = cross_validate(sgd_model_pipeline, X, y, scoring='f1_macro')\n",
        "\n",
        "sgd_clf_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([3.03938246, 4.57707596, 4.3450129 , 3.01535845, 3.03911781]),\n",
              " 'score_time': array([0.76280284, 1.0842104 , 0.70577145, 0.72756815, 0.73754811]),\n",
              " 'test_score': array([0.48182998, 0.48182998, 0.48182998, 0.48178795, 0.48178795])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPZHFbH7l0Bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c483965-2b8a-428f-b3ee-d7f0a68a4c32"
      },
      "source": [
        "# Create a pipeline using our fastText mean embedding vectorizer and a stochastic extra random forest classifier.\n",
        "extra_tree_clf_pipeline = Pipeline([(\"ft_word_vectorizer\", MeanEmbeddingVectorizer(word_vector_dictionary)),\n",
        "                                    (\"Extra_Tree_Clf\", ExtraTreesClassifier(n_estimators=200))])\n",
        "\n",
        "# Use cross validation to calculate the f1_score of the pipeline above.\n",
        "extraTree_clf_score = cross_validate(extra_tree_clf_pipeline, X, y, scoring='f1_macro')\n",
        "\n",
        "extraTree_clf_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([11.76157546, 12.0076077 , 11.87757182, 11.78357434, 11.85364008]),\n",
              " 'score_time': array([1.05904984, 1.02256656, 1.02594709, 1.04065871, 1.02431607]),\n",
              " 'test_score': array([0.68917414, 0.6694044 , 0.67584249, 0.67206223, 0.68398458])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF_6VTifmmDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11e5c71-55f8-4641-d468-d3553622b3f6"
      },
      "source": [
        "# Create a pipeline using our fastText mean embedding vectorizer and a multi-layer perceptron classifier.\n",
        "mlp_pipeline = Pipeline([(\"ft_word_vectorizer\", MeanEmbeddingVectorizer(word_vector_dictionary)),\n",
        "                         (\"mlp_clf\", MLPClassifier())])\n",
        "\n",
        "# Use cross validation to calculate the f1_score of the pipeline above.\n",
        "mlp_clf_score = cross_validate(mlp_pipeline, X, y, scoring='f1_macro')\n",
        "\n",
        "mlp_clf_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([ 63.17506194, 151.14886594, 101.47165012, 108.33660197,\n",
              "         58.32573652]),\n",
              " 'score_time': array([0.95613837, 1.05994725, 1.05627894, 1.05085969, 1.02306342]),\n",
              " 'test_score': array([0.48182998, 0.52879689, 0.51821786, 0.48178795, 0.48178795])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rl_ByT5oTYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb088c5-ec23-40f2-ae09-92a4787c062b"
      },
      "source": [
        "# Create a pipeline using our fastText mean embedding vectorizer and a multi-layer perceptron classifier.\n",
        "boost_pipeline = Pipeline([(\"ft_word_vectorizer\", MeanEmbeddingVectorizer(word_vector_dictionary)),\n",
        "                           (\"lgbm_clf\", LGBMClassifier(n_estimators=200))])\n",
        "\n",
        "# Use cross validation to calculate the f1_score of the pipeline above.\n",
        "lbgm_clf_score = cross_validate(boost_pipeline, X, y, scoring='f1_macro')\n",
        "\n",
        "lbgm_clf_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([8.84438562, 8.76633883, 8.81909418, 8.79916406, 8.78158092]),\n",
              " 'score_time': array([0.78064919, 0.76951694, 0.76265335, 0.78558946, 0.7532897 ]),\n",
              " 'test_score': array([0.66144233, 0.66000512, 0.65596638, 0.64262222, 0.65883131])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtdX7k2aS6gc"
      },
      "source": [
        "### In the section above we used fastText word vectors created using the 'skipgram' unsupervised modeling technique in a Scikit-learn pipeline as an input other supervised models. \n",
        "\n",
        "### In this section we recreate the fastText word vectors, this time using the 'cbow' unsupervised modeling technique, and again use them as inputs to the same supervised models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgNwkvj-S69J"
      },
      "source": [
        "# Location to save the file of learned word vector representations\n",
        "word_vector_model_cbow_filepath = r\"/content/drive/MyDrive/Programming/Colab Notebooks/Coding_Dojo/Twitter_Sentiment_Project/fastText_Models/unsupervised_model_cbow.bin\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnAsEqc6S8r1"
      },
      "source": [
        "# Use a cbow model to create word vector representations of every word in the tweets.\n",
        "unsupervised_model_cbow = fasttext.train_unsupervised(unlabeled_tweet_filepath, model='cbow')\n",
        "\n",
        "# Save the learned word vector representations.\n",
        "unsupervised_model_cbow.save_model(word_vector_model_cbow_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjowRBOvS-7J"
      },
      "source": [
        "# Load the cbow fastText word vector model.\n",
        "ft_model_cbow = load_model(word_vector_model_cbow_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSqjeBvhTCaO"
      },
      "source": [
        "# Create a dictionary mapping each unique word to its fastText word vector.\n",
        "word_vector_dictionary_cbow = {word : ft_model_cbow.get_word_vector(word) for word in unique_words}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyi1jn_oTEk0",
        "outputId": "f9abc018-6722-42ee-db5b-71da61c12ac4"
      },
      "source": [
        "# Create a pipeline using our fastText mean embedding vectorizer and a stochastic gradient decent classifier.\n",
        "sgd_model_pipeline_cbow = Pipeline([(\"ft_word_vectorizer\", MeanEmbeddingVectorizer(word_vector_dictionary_cbow)),\n",
        "                                    (\"SGD_Clf\", SGDClassifier())])\n",
        "\n",
        "# Use cross validation to calculate the f1_score of the pipeline above.\n",
        "sgd_clf_cbow_score = cross_validate(sgd_model_pipeline_cbow, X, y, scoring='f1_macro')\n",
        "\n",
        "sgd_clf_cbow_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([3.05295968, 3.99344063, 4.37372613, 3.13203883, 2.98276353]),\n",
              " 'score_time': array([0.71279097, 0.96511126, 0.98486471, 0.7162931 , 0.70252132]),\n",
              " 'test_score': array([0.48182998, 0.48182998, 0.48182998, 0.48178795, 0.48178795])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bhFbBBjTOkM",
        "outputId": "559c722d-1ad4-499d-ba9f-a46fc365a602"
      },
      "source": [
        "# Create a pipeline using our fastText mean embedding vectorizer and a stochastic extra random forest classifier.\n",
        "extra_tree_clf_pipeline_cbow = Pipeline([(\"ft_word_vectorizer\", MeanEmbeddingVectorizer(word_vector_dictionary_cbow)),\n",
        "                                         (\"Extra_Tree_Clf\", ExtraTreesClassifier(n_estimators=200))])\n",
        "\n",
        "# Use cross validation to calculate the f1_score of the pipeline above.\n",
        "extraTree_clf_cbow_score = cross_validate(extra_tree_clf_pipeline_cbow, X, y, scoring='f1_macro')\n",
        "\n",
        "extraTree_clf_cbow_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([11.97788239, 12.13678455, 11.87558174, 11.88341928, 12.41749525]),\n",
              " 'score_time': array([1.05648184, 1.04730582, 1.03632307, 1.05318975, 1.03329182]),\n",
              " 'test_score': array([0.68917414, 0.66787767, 0.67433512, 0.66750442, 0.6825124 ])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoqDTPc8TUz3",
        "outputId": "87004922-ffda-4b67-efb6-abc85f7a87eb"
      },
      "source": [
        "# Create a pipeline using our fastText mean embedding vectorizer and a multi-layer perceptron classifier.\n",
        "mlp_pipeline_cbow = Pipeline([(\"ft_word_vectorizer\", MeanEmbeddingVectorizer(word_vector_dictionary_cbow)),\n",
        "                              (\"mlp_clf\", MLPClassifier())])\n",
        "\n",
        "# Use cross validation to calculate the f1_score of the pipeline above.\n",
        "mlp_clf_score_cbow = cross_validate(mlp_pipeline_cbow, X, y, scoring='f1_macro')\n",
        "\n",
        "mlp_clf_score_cbow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([72.05164409, 19.39311123, 50.95842099, 44.7173655 , 57.14424276]),\n",
              " 'score_time': array([1.02342415, 0.79099369, 0.99399972, 1.0319469 , 0.97240925]),\n",
              " 'test_score': array([0.48182998, 0.48182998, 0.48182998, 0.48178795, 0.48178795])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PZq1F9cTbzc",
        "outputId": "0e2a37fe-9fb8-4d6c-b4cc-884c2e7b9e85"
      },
      "source": [
        "# Create a pipeline using our fastText mean embedding vectorizer and a multi-layer perceptron classifier.\n",
        "boost_pipeline_cbow = Pipeline([(\"ft_word_vectorizer\", MeanEmbeddingVectorizer(word_vector_dictionary_cbow)),\n",
        "                                (\"lgbm_clf\", LGBMClassifier(n_estimators=200))])\n",
        "\n",
        "# Use cross validation to calculate the f1_score of the pipeline above.\n",
        "lbgm_clf_score_cbow = cross_validate(boost_pipeline_cbow, X, y, scoring='f1_macro')\n",
        "\n",
        "lbgm_clf_score_cbow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([8.30938506, 8.31539774, 8.37187767, 8.28513646, 8.25943112]),\n",
              " 'score_time': array([0.77977586, 0.76945925, 0.75384355, 0.76340342, 0.7754581 ]),\n",
              " 'test_score': array([0.63844614, 0.63746201, 0.63421533, 0.62205726, 0.64918614])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}